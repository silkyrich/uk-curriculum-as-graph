# Gap Analysis: Y4 English — Grammar in Context

**Teacher**: Mr. Kowalski (Y4, Manchester)
**Cluster**: `EN-Y4-D007-CL001` — *Extend sentences with conjunctions, fronted adverbials and direct speech punctuation*
**Content Vehicle**: `EN-Y4-CV001` — *Adventure Narrative: The Iron Man*
**Date**: 2026-02-23

---

## Section-by-Section Analysis

### 1. Learning Objectives — ✅ Fully supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Statutory objectives | All 4 concept nodes have full NC wording | Nothing missing | Lesson-specific phrasing only |
| Concept type | skill / knowledge classification on each concept | — | — |
| Teaching weight | Weights 2-3 across concepts (useful for emphasis) | — | — |

**Notes**: This is the graph's strongest area. Every concept has its statutory curriculum statement stored verbatim. The concept_type (skill vs knowledge) helps me plan activities — skills need practice, knowledge needs explicit teaching. Teaching weight tells me C055 (weight 2) needs less emphasis than C052/C056/C057 (weight 3).

---

### 2. Success Criteria — ✅ Fully supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Vehicle success criteria | 4 criteria in `success_criteria` property | No differentiated criteria (support/extension) | Expanded into child-friendly checklist; added Patterns lens criterion |
| Assessment guidance | Full assessment paragraph on vehicle | — | — |

**Notes**: The vehicle's success criteria are written at teacher level, not child level. I had to rephrase them as "I can..." statements. The criteria also don't distinguish expected from greater depth — they're a flat list.

---

### 3. Prior Knowledge Required — ✅ Fully supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Y3 prerequisites | All 4 PREREQUISITE_OF links with named concepts | No diagnostic questions for prior knowledge | Quick-check whiteboard questions |
| Progression language | Teaching guidance explains Y3→Y4 extension | — | — |

**Notes**: The prerequisite chain is one of the graph's most useful features for English. Grammar is cumulative — knowing exactly what children should have learned in Y3 (e.g. basic fronted adverbials) versus what's new in Y4 (wider range: time, place, manner, frequency) is essential. The teaching guidance on each concept explicitly addresses this progression.

---

### 4. Lesson Structure with Timings — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Pedagogy sequence | 5-phase model from learner profile | No classroom timing breakdowns | All timings (10/35/15 split) |
| Session length | 15-25 min (platform sessions) | No classroom lesson format guidance | Adapted to 60-min lesson |
| Scaffolding level | "moderate" | No specific scaffold descriptions | All scaffolding activities |
| Productive failure | "appropriate ✓" for Y4 | No examples of productive failure tasks for English | Pattern hunt as challenge problem |

**Notes**: The 5-phase pedagogy sequence (challenge → exploration → instruction → independent → retrieval) is designed for adaptive platform sessions, not classroom teaching. But it actually translates well to a talk-for-writing lesson structure:
- Challenge problem → text encounter (read without pre-teaching)
- Exploration → shared analysis (discuss grammar patterns in text)
- Instruction → modelled writing (teacher demonstrates)
- Independent practice → write own text
- Retrieval → peer review + exit ticket

The graph gives me the pedagogical principles but not the classroom practicalities. A Y4 English lesson needs: talk partner time, modelled writing time, independent writing time, and reading aloud time. None of these are in the graph, but the 5-phase model accommodates them.

---

### 5. Key Vocabulary with Definitions — ✅ Fully supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Concept vocabulary | 27 terms across 4 concepts | No child-friendly definitions | Simplified definitions |
| Vehicle definitions | 8 literary terms | — | — |
| Grammatical terminology | Listed in teaching guidance + NC statutory appendix | — | — |

**Notes**: The vocabulary data is exceptionally rich. Each concept lists 8-12 key terms. The vehicle adds literary terms (protagonist, antagonist, dialogue, suspense). The teaching guidance often explains how to introduce terminology in context. For grammar teaching specifically, this is better than most published schemes because the vocabulary is tied to specific concepts rather than presented as a generic word list.

---

### 6. Resources and Materials Needed — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Core text name | "The Iron Man by Ted Hughes" | No chapter/page references | Passage selection |
| Extension text | "Stig of the Dump by Clive King" | No explanation of why this pairs | — |
| Genre | adventure narrative | — | — |
| Text features | 4 features listed | No example passages showing features | — |
| Grammar focus | 3 grammar types listed | No annotated examples | — |
| Reading level | "Year 4" | No Lexile/readability score for texts | — |
| Physical resources | — | Entirely missing | All classroom resources |

**Notes**: The vehicle gives me a text name and genre — helpful but insufficient. As an English teacher, I need to know:
1. **Which chapters** of The Iron Man best demonstrate these grammar patterns?
2. **What page/passage** should I use for shared reading?
3. **Is the reading level right?** (The Iron Man is actually quite challenging for some Y4 readers — the vehicle says "Year 4" but doesn't give a Lexile score)
4. **Are there copyright-cleared extracts** available?

The `suggested_texts` property is a good start. The `text_features` property tells me what to look for. But the gap between "use The Iron Man" and "here is a passage from The Iron Man that demonstrates fronted adverbials, multi-clause sentences, and direct speech" is significant for English planning.

---

### 7. Differentiation (Support + Extension) — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Hint tier model | 3 tiers from learner profile | No English-specific scaffold examples | Sentence frames, word banks, checklists |
| Common misconceptions | 12+ specific misconceptions | — | — |
| Progression points | Teaching guidance identifies extension challenges | No "working towards / expected / greater depth" descriptors | Extension activities |
| DifficultyLevel nodes | Not available for English (Y3 Maths pilot only) | Full difficulty tier data | — |

**Notes**: The 3-tier hint model from the learner profile is useful as a framework, but the content of each tier had to be English-specific. The common misconceptions are the real differentiation gold — knowing that "children commonly forget the comma after a fronted adverbial" tells me exactly what my support group needs, and knowing that "interrupted speech is particularly challenging" tells me what my extension group should tackle.

The absence of DifficultyLevel nodes for English is significant. For Y3 Maths (I hear from Brennan), there are entry → developing → expected → greater_depth tiers with example tasks for each. If these existed for English grammar, I'd know exactly what "expected" looks like for direct speech punctuation versus "greater depth." This is essential for English assessment and differentiation.

---

### 8. Assessment Opportunities — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Vehicle assessment guidance | Full paragraph | No rubric or marking criteria | All assessment methods |
| Success criteria | 4 criteria | No levelled criteria | — |
| Misconceptions as assessment targets | 12+ specific misconceptions | — | — |
| DifficultyLevel descriptors | Not available for English | Would enable "expected standard" benchmarking | — |
| Example pupil work (annotated) | — | Entirely missing | — |

**Notes**: The graph gives me what to assess (success criteria) and what errors to look for (misconceptions), but not how to assess or what good looks like. For English, "what does good writing look like?" is the central assessment question, and it can only be answered with example texts at different standards. The vehicle's assessment guidance is teacher-facing and describes outcomes rather than criteria.

---

### 9. Common Misconceptions to Address — ✅ Fully supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Concept misconceptions | 3-4 per concept, highly specific | — | Addressing strategies only |
| Error patterns | Described in detail | — | — |
| Frequency indicators | Some ("commonly", "frequently", "particularly challenging") | No quantified data | — |

**Notes**: This is the graph's second strongest area for English (after learning objectives). The misconceptions are clearly written by someone who has taught or observed Y4 grammar. Examples:
- "Children frequently misplace speech marks, particularly forgetting to close them or placing them around the reporting clause as well as the speech" — this is exactly what I see in my classroom.
- "The interrupted speech pattern is particularly challenging" — this tells me to save it for extension.
- "Children may overuse fronted adverbials, starting every sentence with one" — I can pre-empt this in my modelling.

The addressing strategies are mine (physical clapping for commas, "speech sandwich" analogy), but the graph tells me precisely what to address.

---

### 10. Worked Examples / Model Texts — ❌ Not supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Text titles | 2 suggested texts | Actual text extracts | — |
| Text features | 4 features described | Annotated examples showing features | — |
| Grammar focus | 3 grammar types named | Sentences demonstrating each type | — |
| Model writing | — | Entirely missing | Full model passage |
| Writing frames | — | Entirely missing | — |
| Annotated examples | — | Entirely missing | — |

**Notes**: This is the critical gap for English/literacy planning. In Maths, a "worked example" is a calculation with steps — it can be generated from the concept definition. In English, a "worked example" is:

1. **A model text** — a passage of writing that demonstrates the target grammar features
2. **An annotated extract** — a real text with grammar patterns highlighted and labelled
3. **A writing frame** — a scaffold showing how to structure a piece of writing
4. **Before/after examples** — showing a plain sentence transformed using the grammar pattern

None of these exist in the graph. The vehicle tells me to use The Iron Man, but doesn't give me a single line from it (copyright issues notwithstanding). For the platform to generate English lessons, it would need at least:
- **Grammar pattern exemplars**: 3-5 sentences demonstrating each grammar concept at the correct level
- **Model paragraphs**: Short passages showing multiple grammar patterns working together
- **Common/improved pairs**: "She walked home. She was tired." → "Although she was tired, she walked home slowly."

This is the most labour-intensive data to create, but it's the difference between a usable English lesson and a lesson skeleton.

---

### 11. Practice Activities / Writing Tasks — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Writing outcome | Vehicle: "500-700 word adventure narrative" | No lesson-sized writing tasks | Scaled tasks |
| Interaction types | 6 primary + 4 secondary from learner profile | No English-specific activity templates | All activity designs |
| Pedagogy sequence | 5-phase model | No mapped activities per phase | Phase-activity mapping |

**Notes**: The interaction types from the learner profile are designed for a digital platform. For classroom English teaching, I need:
- **Shared reading** activities (read aloud, discuss, annotate)
- **Talk-for-writing** activities (oral rehearsal, actions, retelling)
- **Shared writing** activities (teacher scribing, children contributing)
- **Guided writing** activities (small group with teacher support)
- **Independent writing** activities (individual composition)

These are the core English teaching modes and none appear in the graph. The interaction types (text_highlight, drag_reorder, matching_pairs) could support some of these, but they're platform interactions, not classroom pedagogies. The English teaching cycle of read → talk → plan → write → edit → publish is missing as a structural model.

---

### 12. Cross-Curricular Links — ⚠️ Partially supported

| Aspect | Available data | Missing data | What I invented |
|---|---|---|---|
| Within-English CO_TEACHES | 11 co-teachable concepts identified | — | — |
| Reading-Writing cycle | Vehicle DELIVERS across domains (reading + writing + grammar) | No explicit read→write mapping | — |
| Cross-subject links | — | No English↔History, English↔Science concept links | Cross-subject writing tasks |
| ReadingSkill concept links | — | No Concept→ReadingSkill relationships | — |

**Notes**: The CO_TEACHES relationships are useful for within-English planning — they tell me that multi-clause sentences naturally pair with fronted adverbials and expanded noun phrases (which is true). The vehicle's cross-domain DELIVERS links are interesting: EN-Y4-CV001 delivers reading concepts (inference, prediction) AND writing concepts (narrative elements), mapping the read→write teaching cycle.

What's missing is cross-subject links. English is the subject that connects to everything — children write in History, read in Science, discuss in Geography. The graph has DEVELOPS_SKILL links for Science→WorkingScientifically and History→HistoricalThinking, but no equivalent for English→ReadingSkill at concept level.

---

## Overall Readiness Score

### **6/10 — Good structural foundation, weak on English-specific content**

The graph excels at:
- **Curriculum structure** (objectives, prerequisites, vocabulary) — all excellent
- **Misconceptions** — genuinely useful, clearly written by practitioners
- **Pedagogical framework** (learner profile, hint tiers, feedback style) — well-designed
- **Content vehicle metadata** (text names, genres, features, grammar focus) — good starting point
- **Thinking lenses** (Patterns lens for grammar) — appropriate and well-applied
- **CO_TEACHES relationships** — useful for English planning specifically

The graph falls short on:
- **Model texts and worked examples** — the single biggest gap for English
- **Text extracts and passages** — essential for reading/writing teaching
- **Writing frames and scaffolds** — needed for differentiation
- **DifficultyLevel nodes** — not yet available for English (Y3 Maths pilot only)
- **English-specific interaction types** — platform interactions don't map to English teaching modes
- **Cross-subject concept links** — English connects to everything but the graph doesn't model this

---

## English-Specific Gaps

These are gaps that affect English/literacy planning specifically, beyond the general gaps noted above:

### 1. No text extracts or passage bank
English teaching is **text-driven**. Every lesson starts with a text. The graph names texts (The Iron Man) but provides no passages, no annotated extracts, no copyright-cleared materials. A Maths lesson can be generated from concept + worked example. An English lesson cannot be generated without an actual text to read.

### 2. No model writing at different standards
The DifficultyLevel nodes (entry → developing → expected → greater_depth) with example_task and example_response would be transformative for English. For grammar, this would look like:
- **Entry**: "The Iron Man walked. He was big." (simple sentences only)
- **Developing**: "The Iron Man walked because he was looking for food." (conjunction but limited range)
- **Expected**: "Although the farmers were terrified, the Iron Man strode silently across the field." (fronted adverbial + subordinating conjunction + comma)
- **Greater depth**: "'I think it's coming back,' whispered Hogarth, while the enormous figure rose beyond the trees." (all four patterns in one sentence)

### 3. No grammar progression spine
The prerequisite links (Y3-C054 → Y4-C052) show concept-level progression, but there's no explicit grammar progression model: what grammatical structures do children learn in what order? This exists implicitly in the cluster sequencing (D007-CL001 → CL002 → CL003 → CL004) but it's not a queryable grammar spine.

### 4. No reading level metadata on suggested texts
The vehicle says "reading level: Year 4" but The Iron Man is arguably challenging for some Y4 readers (long sentences, abstract themes, archaic vocabulary). A Lexile score, word count, or sentence complexity score on each suggested text would help teachers make informed text selections.

### 5. No writing frames or scaffolds
The learner profile mentions "3 hint tiers" and "moderate scaffolding" but provides no English-specific scaffold types: sentence starters, paragraph frames, genre checklists, connective mats. These are the physical resources that differentiate English teaching.

### 6. No talk-for-writing or oracy structures
The spoken language domain (EN-Y4-D001) has its own clusters, but these aren't linked to the reading/writing domains. In practice, talk is the bridge: children talk about texts before they write. The graph models reading, writing, and speaking as separate domains without modelling the read→talk→write cycle.

---

## Top 5 Data Additions

### 1. DifficultyLevel nodes for English concepts (HIGH PRIORITY)
Extend the Y3 Maths pilot to English grammar concepts. Each concept (e.g. EN-Y4-C056 Fronted adverbials) would have 3-4 DifficultyLevel sub-nodes with `example_task`, `example_response`, `common_errors`, and `description` at each level. This single addition would close the biggest gap for English assessment and differentiation.

### 2. Grammar exemplar sentences on each Concept node (HIGH PRIORITY)
Add a `model_sentences` array property to grammar Concept nodes. 3-5 short sentences demonstrating the concept at the correct year group level. These are not copyrighted text extracts — they're generic grammar examples. E.g., for EN-Y4-C056:
- *"Cautiously, the fox crept through the garden."*
- *"After a long day at school, Maya flopped onto the sofa."*
- *"Beyond the hedge, something was rustling."*

### 3. Text readability metadata on ContentVehicle nodes (MEDIUM PRIORITY)
Add `lexile_score`, `word_count`, `avg_sentence_length`, and `reading_age` properties to each ContentVehicle or to a new `:TextResource` node linked to vehicles. This would let the platform match texts to the learner profile's Lexile range (300-500L for Y4).

### 4. Writing frame templates on ContentVehicle or ConceptCluster nodes (MEDIUM PRIORITY)
Add a `writing_scaffolds` property or linked `:WritingFrame` nodes containing:
- Sentence starters appropriate to the grammar focus
- Paragraph structure templates (e.g. persuasive: point → evidence → explanation)
- Genre checklists ("Does your adventure narrative have: opening, build-up, climax, resolution?")

### 5. READS_BEFORE / WRITES_AFTER cross-domain relationships (LOWER PRIORITY)
Model the read→write teaching cycle explicitly. When EN-Y4-CV001 is used, children read for comprehension (D003 concepts) before they write narratives (D006 concepts) using grammar (D007 concepts). A `READS_BEFORE` or `INFORMS_WRITING` relationship from reading clusters to writing clusters would model this essential English teaching sequence.

---

## Specific New Entities and Properties

### New node type: `:TextResource`
```
(:TextResource {
  resource_id: 'TR-EN-Y4-001',
  title: 'The Iron Man',
  author: 'Ted Hughes',
  lexile_score: 780,
  reading_age: '8-10',
  word_count: 12000,
  genre: 'adventure narrative',
  chapter_count: 5,
  copyright_status: 'in_copyright',
  available_extracts: ['Chapter 1: The Coming of the Iron Man', 'Chapter 5: The Iron Man's Challenge']
})
```
**Relationships**: `(:ContentVehicle)-[:USES_TEXT]->(:TextResource)`, `(:TextResource)-[:SUITABLE_FOR]->(:Year)`

### New property: `model_sentences` on Concept nodes
```cypher
// EN-Y4-C056 (Fronted adverbials)
SET c.model_sentences = [
  'Cautiously, the fox crept through the garden.',
  'After a long day, Maya flopped onto the sofa.',
  'Beyond the hedge, something was rustling.',
  'Every morning, the birds sang outside her window.',
  'With great care, he placed the egg back in the nest.'
]
```

### New property: `writing_scaffolds` on ConceptCluster nodes
```cypher
// EN-Y4-D007-CL001
SET cc.writing_scaffolds = [
  'Sentence frame: _________ [fronted adverbial], the _________ [noun] _________ [verb].',
  'Speech frame: "_________ ," said _________ , "_________ ."',
  'Conjunction frame: _________ [main clause] although/while/because _________ [subordinate clause].'
]
```

### New property: `progression_note` on PREREQUISITE_OF relationships
```cypher
// EN-Y3-C058 -[:PREREQUISITE_OF]-> EN-Y4-C056
SET r.progression_note = 'Y3: basic fronted adverbials (time: Later, Place: Outside). Y4: wider range including manner (Cautiously), frequency (Every morning), and adverbial phrases (With great care).'
```

### Extend DifficultyLevel to English (priority pilot: Y4 Grammar)
Same structure as Y3 Maths pilot:
```
(:DifficultyLevel {
  level_id: 'EN-Y4-C056-DL3',
  concept_id: 'EN-Y4-C056',
  level_number: 3,
  label: 'expected',
  description: 'Uses a variety of fronted adverbials (time, place, manner) with correct comma placement',
  example_task: 'Rewrite these sentences by adding a fronted adverbial to each opening.',
  example_response: 'Nervously, the farmer peered over the hedge. Beyond the dark forest, the Iron Man waited.',
  common_errors: 'Forgetting comma; using only single-word adverbials; starting every sentence with a fronted adverbial'
})
```

---

## Comparison with Other Subjects

English planning has fundamentally different needs from Maths and Science:

| Need | Maths | Science | English |
|---|---|---|---|
| Worked examples | Calculations (generatable) | Diagrams + method | **Model texts** (must be authored) |
| Core resource | Number line, manipulatives | Equipment list | **A specific text** (must be selected) |
| Differentiation | Adjust numbers/complexity | Adjust variables | **Adjust text level + scaffold** |
| Assessment | Right/wrong answer | Method + conclusion | **Quality of writing** (holistic) |
| Cross-curricular | Self-contained | English for report writing | **Connects to everything** |

The graph was clearly designed with Maths and Science as primary use cases (DifficultyLevel pilot is Maths, worked examples are calculations, equipment lists exist for Science). English requires a fundamentally text-centric data model that doesn't yet exist. The content vehicles are a good step — they name texts and genres — but the next step is providing the actual content that makes English lessons teachable.

---

## Teaching Artefacts Needed

**The question**: What do I actually need to walk into my Y4 classroom and teach this grammar lesson? The lesson plan is step 1 — what artefacts close the gap between "plan" and "ready to teach"?

### Top 5 (priority order for Y4 English)

#### 1. Model Text Display / Annotated Extract (IWB slide or A3 poster)
**What it is**: A passage (8-12 sentences) from *The Iron Man* — or written in that style — displayed large on the interactive whiteboard, with grammar patterns colour-coded: conjunctions in blue, fronted adverbials in green, speech punctuation in red.

**Why it matters most**: This IS the lesson. English grammar teaching starts with a text. Children read it, discuss it, identify patterns in it, then write their own version. Without this artefact, I'm standing at the board writing passages by hand in real time — which takes 10 minutes of teaching time and produces messy results. Every English lesson in every school in the country starts with a text on the board.

**What the graph provides**: Text title, genre, text features, grammar focus. **What's missing**: The actual passage, the annotations, the colour-coding.

**Could the platform generate this?** Partially. If the graph had `model_sentences` per concept and `model_paragraphs` per cluster, the platform could compose and annotate a passage. But the passage needs to be coherent narrative — not just grammar sentences stapled together — so it needs authoring or at minimum human curation.

#### 2. Differentiated Writing Scaffolds (printed handouts, 3 levels)
**What it is**: Three versions of a writing scaffold for the independent writing task:
- **Support**: Sentence frames with gaps — *"_________ [fronted adverbial], the Iron Man _________ [verb]. '_________ !' _________ [reporting verb] Hogarth, _________ [conjunction] _________."*
- **Expected**: A planning grid — "Your passage needs: 1 fronted adverbial (comma!), 1 subordinating conjunction, 1 line of direct speech. Plan your 4-6 sentences here."
- **Greater depth**: A quality checklist — "Have you varied your sentence openings? Used at least 3 different conjunctions? Included interrupted speech? Made deliberate choices about where to use short vs long sentences?"

**Why it matters**: In a class of 30, I have children at 3-4 different levels. Without printed scaffolds, I'm running between tables explaining the same thing six times. Scaffolds free me to focus on the children who need direct support. Every English lesson needs differentiated scaffolds — they're the most-printed resource in primary English teaching.

**What the graph provides**: 3-tier hint model, common misconceptions (which identify what each level struggles with), concept teaching guidance. **What's missing**: The actual scaffold content, formatted for printing.

**Could the platform generate this?** Yes — this is very generatable. The graph already has the misconceptions (which define support targets), the vocabulary (which populates word banks), and the concept structure (which defines what expected/extension look like). DifficultyLevel nodes would make this even better.

#### 3. Grammar Toolkit Word Mat (laminated A4, one per table)
**What it is**: A single-page reference card with:
- Subordinating conjunctions organised by function (time: when, while, until, after / cause: because, since, as / contrast: although, even though / purpose: so that, in order to)
- Fronted adverbial examples organised by type (time: Later that day, / place: Beyond the fence, / manner: Cautiously, / frequency: Every morning,)
- Direct speech punctuation rules with visual diagrams
- Key grammatical terminology with child-friendly definitions

**Why it matters**: Children need reference points during independent writing. A word mat stays on the table the whole lesson — children glance at it, try a conjunction, check their punctuation. It reduces the cognitive load of remembering grammar rules while they're also composing content. In my classroom, every table has a grammar mat — it's the single most-used resource after the pencil.

**What the graph provides**: 27 vocabulary terms across the 4 concepts, concept definitions, conjunction/adverbial categorisations in teaching guidance. **What's missing**: Formatted layout, visual design, child-friendly presentation.

**Could the platform generate this?** Absolutely. The vocabulary data is rich enough to populate this entirely from the graph. The teaching guidance even categorises conjunctions by function and adverbials by type. This is the lowest-hanging fruit — high value, low authoring effort.

#### 4. Assessment Grid / Marking Rubric (teacher reference, A4)
**What it is**: A grid showing what "working towards", "expected", and "greater depth" looks like for this specific lesson's objectives:

| Objective | Working towards | Expected | Greater depth |
|---|---|---|---|
| Multi-clause sentences | Uses "and" / "because" only | Uses 3+ different subordinating conjunctions | Varies clause order for effect; uses concessive conjunctions |
| Fronted adverbials | Occasionally uses, may forget comma | Uses time/place/manner adverbials with comma | Uses adverbial phrases; varies deliberately; avoids overuse |
| Direct speech | Attempts speech marks, errors in placement | Correct punctuation: speech-first and speech-after patterns | Interrupted speech; varied reporting verbs; speech advances plot |

**Why it matters**: English marking is holistic and subjective — two teachers can disagree on whether a piece of writing is "expected" or "greater depth." A rubric makes marking faster, more consistent, and defensible to parents. It also shows children what they're aiming for. Without it, I'm marking 30 pieces of writing using gut feeling.

**What the graph provides**: Success criteria (vehicle), misconceptions (which define "working towards" errors), concept progression (teaching guidance describes expected vs extension). **What's missing**: Formatted rubric with levelled descriptors. DifficultyLevel nodes would directly supply these.

**Could the platform generate this?** Yes, IF DifficultyLevel nodes existed for English. The Maths pilot (Y3) has exactly this structure — entry/developing/expected/greater_depth with example_task and common_errors at each level. Extending this to English grammar is my #1 recommendation.

#### 5. Sentence Surgery Cards (printed and cut, class set)
**What it is**: Physical cards for the "Sentence Surgery" guided practice activity — pre-made sentence components that children physically reorder:
- Set A (support): 4 cards making one multi-clause sentence — *[Although it was dark] [,] [Hogarth crept forward] [.]*
- Set B (expected): 6 cards making a sentence with fronted adverbial + speech — *[Nervously] [,] [he whispered] [,] ["I can see it"] [.]*
- Set C (extension): 8 cards making interrupted speech with a conjunction — *["I think] [it's coming back] [,"] [said Hogarth] [,] ["because] [the ground is shaking] [."]*

**Why it matters**: Physical manipulation helps children internalise punctuation rules. They can see that the comma goes inside the speech marks because the card won't fit anywhere else. It also makes grammar active rather than passive — children are constructing sentences, not just identifying features. This is 10 minutes of my lesson and needs to be ready to go.

**What the graph provides**: Concept definitions (what the sentence patterns are), misconceptions (what errors children make), interaction type guidance (drag_reorder: "4-6 items for Y4"). **What's missing**: The actual sentence content, formatted for card printing.

**Could the platform generate this?** Yes. If the graph had `model_sentences` per concept, the platform could decompose them into components and generate card sets at different difficulty levels. The drag_reorder interaction type already describes the pedagogical design — it just needs content to populate it.

### Honourable mentions (not in top 5 but useful)

- **Knowledge organiser** (A4, for topic book): Summary of grammar rules, vocabulary, and examples for the whole unit. Graph could generate from concept data + vocabulary.
- **Homework sheet**: 5-6 practice sentences for parents to support at home. Graph could generate from model_sentences + misconceptions.
- **Working wall display** (A3 poster): Enlarged versions of the grammar rules and examples, built up over the unit. Graph could generate section by section as clusters progress.
- **Parent-facing summary**: "This week in English, your child is learning about..." with examples they can practise at home. Graph has enough metadata for this.

### What I DON'T need generated

- **Presentation slides / PowerPoint**: I project the text extract and annotate live — slides would make the lesson feel scripted and remove the shared discovery element.
- **Videos / animations**: Grammar is best taught through text, not video. Children need to read and manipulate language, not watch it.
- **Manipulative templates** (place value cards, fraction strips): These are Maths resources. English doesn't use manipulatives in this way (the sentence cards above are the English equivalent).

### Summary: Artefact Generation Feasibility

| Artefact | Priority | Could generate from current graph? | Could generate with proposed additions? |
|---|---|---|---|
| Model text display | 1 | No — no text content | Partially — needs `model_sentences` + `model_paragraphs` + human curation |
| Differentiated writing scaffolds | 2 | Partially — misconceptions + vocabulary available | Yes — DifficultyLevels would define each tier |
| Grammar toolkit word mat | 3 | Mostly — vocabulary + categorisations available | Yes — fully generatable |
| Assessment grid / marking rubric | 4 | Partially — success criteria + misconceptions | Yes — DifficultyLevels would directly supply level descriptors |
| Sentence surgery cards | 5 | No — no model sentences | Yes — `model_sentences` decomposed into components |

**Bottom line**: 3 of my top 5 artefacts could be generated TODAY with minor formatting work on existing graph data (scaffolds, word mat, assessment grid partially). The other 2 need the `model_sentences` and `DifficultyLevel` data additions I've already recommended. If both were added, 4 of 5 artefacts become fully generatable and the 5th (model text display) becomes partially generatable with human curation.

---

*Generated from UK Curriculum Knowledge Graph data. Analysis by Mr. Kowalski (Y4 English, simulated teacher review). 2026-02-23.*
