# Gap Analysis: Ms. Brennan -- Y3 Mathematics (Measurement)

**Cluster:** MA-Y3-D005-CL001 -- Measure in mixed units and calculate perimeter
**Date:** February 2026 (V8 review)
**Reviewer:** Ms. Brennan, Y3 class teacher, 8 years experience, mastery approach (Singapore-style)
**Previous review:** V7, same graph version without RepresentationStage data, scored 7.5/10 (different cluster: Fractions)

---

## Score: 8.5 / 10

---

## Section-by-Section Evaluation

### 1. Cluster Overview and Curriculum Context

**What was sufficient:**
- The curriculum context paragraph was excellent. It told me exactly where Y3 measurement sits in the broader progression -- extending KS1 by introducing mm, mixed units, metric equivalences, and perimeter for the first time. I could have copied this paragraph into a medium-term plan without editing it.
- The cluster rationale ("Mixed-unit measurement and perimeter are both applied measurement skills") correctly justified why these two concepts are grouped together.
- The domain progression showing CL001 (this cluster) followed by CL002 (money and time) gave me clear sequencing.
- The thinking lens "Scale, Proportion and Quantity" was well chosen and the rationale explaining *why* it fits ("1 m = 100 cm encodes a scale factor of 100") gave me a genuine pedagogical angle, not just a label.

**What was missing:**
- "Estimated teaching time: None lessons (~None weeks)" -- this field was null. For a two-concept introduction cluster, I would estimate 3-4 lessons across 1-1.5 weeks. This is basic metadata that should be populated.
- Year group line reads "Y3 *(year override -- learner profile reflects this year, not domain anchor)* (None)" -- the "(None)" is a data quality issue. Minor, but sloppy.
- The second thinking lens (Structure and Function, for perimeter) is valid but its question stems ("How does the shape or arrangement help it do its job?") are more suited to Science or DT than to Y3 Maths measurement. The lens description is generic -- it would benefit from a maths-specific worked example of how to use it.

---

### 2. Prerequisite Knowledge

**What was sufficient:**
- The prerequisite link to formal columnar addition (MA-Y3-D002) is correct and important -- children need to add multi-digit numbers to combine measurements.

**What was missing:**
- Only one prerequisite listed. In reality, Y2 measurement is the primary prerequisite for Y3 measurement -- children should already know how to measure length in cm, compare lengths, and use standard units for mass and capacity. This cross-year prerequisite is not modelled.
- No Y2 measurement concept appears anywhere in this context. For my V7 fractions review, the curriculum context at least mentioned "halves and quarters of KS1." Here, there is no mention of prior measurement skills.
- No diagnostic assessment questions to check prerequisite knowledge. I had to invent the warm-up from scratch.

**Verdict:** This is a weaker prerequisite section than the fractions cluster had. Columnar addition is an *auxiliary* prerequisite (you need it to add measurements). The *primary* prerequisite -- "children can measure length in cm and compare lengths" -- is not captured.

---

### 3. Concept Descriptions and Teaching Guidance

**What was sufficient:**
- Both concept descriptions (C030 mixed units, C031 perimeter) were detailed, accurate, and well-written. The C030 description covered all the required metric conversions and explicitly stated that mm is introduced in Y3 -- a detail I would otherwise need to check in the programme of study.
- Teaching guidance was practical and specific: "Use real measuring instruments: rulers in mm/cm/m, kitchen scales in g/kg, measuring jugs in ml/l." This is exactly how I would teach it. The note about "kilo- means 1000" as a pattern across units is a nice pedagogical insight.
- Common misconceptions were specific and actionable: confusing mm and cm, adding mixed units without converting, using the wrong conversion factor. These are the exact misconceptions I see in my classroom every year.

**What was missing:**
- No guidance on the ORDER of teaching within the concept. C030 covers length, mass, AND volume. In practice, I always teach length first (rulers are familiar from Y2), then mass (kitchen scales), then capacity (measuring jugs). The graph treats these as one concept -- a real teacher would split this into 2-3 lessons by measurement type.
- No guidance on how long to spend on this concept. "Weight 3" tells me it is moderately important, but not whether it is a 2-lesson or 4-lesson topic.

---

### 4. DifficultyLevel Quality

**What was sufficient:**
- Four clear tiers (entry/developing/expected/greater depth) with specific, assessable example tasks.
- The progression across tiers was logical and well-calibrated:
  - Entry: measure an object in the correct unit (purely concrete, appropriate for children not yet secure)
  - Developing: record in mixed units and state equivalences (the core Y3 expectation for most children)
  - Expected: add and subtract in mixed units by converting first (the statutory "expected standard")
  - Greater depth: multi-step problems with comparison and conversion (genuine reasoning challenge)
- The example tasks were specific enough to use directly in a lesson or on a worksheet. "A bag weighs 2 kg 400 g. Another bag weighs 1 kg 750 g. What is their total weight?" -- that is a usable classroom question, not a vague description.
- The greater depth task ("A ribbon is 2 m 30 cm long. I cut off 85 cm. How much is left?") is genuinely challenging because it requires conversion before subtraction and the answer must be re-expressed in mixed units.

**What was missing:**
- Only one example task per tier. For differentiated worksheets, I need 4-6 questions per tier. The single exemplar shows me the *standard*, but I still have to generate the practice set myself.
- No worked example steps. The gap I flagged in V7 persists. "A bag weighs 2 kg 400 g plus 1 kg 750 g" -- the answer is 4 kg 150 g, but the STEPS (convert to grams, add, convert back) are not provided. I had to construct the worked example procedure from the teaching guidance prose.
- The `common_errors` field on DifficultyLevel nodes was not shown in the context (or does not exist for these levels). The concept-level misconceptions were good, but I expected to see tier-specific errors too -- e.g. at Entry level, the common error is "reads the ruler from 1 instead of 0."

**Verdict:** DifficultyLevels remain the single most useful data source for lesson planning. The quality here is equivalent to what I saw in V7 for fractions. The calibration is right, the tasks are usable, and the progression is pedagogically sound. The same gaps persist: one example per tier, no worked example steps.

---

### 5. CPA (RepresentationStage) Quality -- NEW SINCE V7

**This is the headline addition.**

**What was sufficient:**
- Three clearly defined stages (Concrete, Pictorial, Abstract) for each concept, with specific descriptions of what children DO at each stage. This is the first time the graph has given me a CPA framework, and it is immediately useful.
- **Resource lists were specific and practical.** For C030 Concrete: "30 cm rulers (mm markings), metre sticks, kitchen scales (g/kg), measuring jugs (ml/l), balance scales, classroom objects to measure." For C031 Concrete: "string, rulers, metre sticks, masking tape (for floor shapes)." These are real classroom resources, not generic suggestions. I could hand this list to a TA and say "set these out before the lesson."
- **Transition cues were genuinely useful.** The transition cue from Concrete to Pictorial for C030 reads: "Child reads measuring instruments accurately in mixed units and converts between units using the x1000 relationship." This describes an OBSERVABLE BEHAVIOUR -- I can watch a child and decide whether they are ready to move on. This is exactly what mastery teaching requires: a clear "readiness to progress" indicator.
- The Pictorial stage for C030 specified "bar models to add and subtract mixed-unit measurements" -- this is the correct pictorial model for this concept. Not a generic diagram, but the specific representation that bridges concrete to abstract.
- The CPA stages mapped naturally onto differentiation tiers. Entry children stay concrete (measuring real objects). Developing children move to pictorial (number lines, bar models). Expected and Greater Depth children work abstractly. The graph didn't state this mapping explicitly, but it fell out naturally from the data. For a mastery teacher, this is gold.

**What was missing:**
- No PHOTOGRAPHS or DIAGRAMS showing what each stage looks like. The descriptions are text-only. A picture of a child using a bar model for mixed-unit addition would be worth 500 words of description. I know this is a data limitation (the graph stores text, not images), but it is worth noting.
- No guidance on how long to spend at each CPA stage. In my lesson I allocated roughly 15 min concrete, 8 min pictorial, and let the abstract emerge in practice. But some children need 2-3 full lessons at the concrete stage before they are ready to move on. The RepresentationStage data implies a linear progression through one lesson, when in practice it might span a week.
- The Pictorial resource list includes "scale-reading worksheets" -- but these do not exist in the graph. They would need to be created. Listing a resource you cannot provide is a minor frustration.
- No explicit CPA progression for the ADDITION/SUBTRACTION of measurements (which is the Expected-level skill). The CPA stages describe measuring and converting, but the step from "I can convert 2 kg 300 g to 2300 g" to "I can add 2 kg 300 g + 1 kg 750 g" has its own CPA progression (combine physical masses on scales -> bar model addition -> abstract column addition with conversion). This intermediate CPA step is missing.

**Overall CPA verdict:** 7/10 for the RepresentationStage data itself. The resource lists and transition cues are genuinely useful additions that did not exist in V7. I used them directly in my lesson plan without modification. The transition cues in particular solved a problem I have been trying to articulate for years: how do you know when a child is ready to move from concrete to pictorial? The graph now answers this with observable behaviours. The gaps are around time-to-spend, visual examples, and CPA for multi-step operations (not just single concepts).

---

### 6. Learner Profile

**What was sufficient:**
- The pedagogy profile session sequence (challenge_problem -> guided_exploration -> worked_example -> independent_practice -> retrieval_practice) structured my lesson directly. I used every phase.
- Productive failure guidance ("Start with a challenge problem -- do not explain first. Let the child attempt independently for 2-3 minutes.") justified my warm-up design.
- Interleaving instruction ("mix this concept with previously mastered material") structured my plenary retrieval questions.
- Feedback profile guidance was specific and usable: name the skill demonstrated, normalise struggle, never compare to other children.
- Interaction types were well-selected for Y3. Pattern Discovery, Drag to Categorise, and Multiple Choice are all appropriate for this age group and this content.
- The maths-specific tools (area_model_multiplication, column_subtraction, number_line_scrubber, place_value_blocks) are relevant -- I used the number line concept in my pictorial phase.

**What was missing:**
- Session length "12-20 minutes" is for digital sessions. My classroom lesson is 45 minutes. The graph still does not model a whole-class lesson structure, and this gap was flagged in V7. Expanding the 15-min digital sequence to a 45-min classroom lesson required significant professional judgment.
- No guidance on concrete manipulative deployment in a classroom context (how many per table, rotation strategy, TA role). The CPA resource lists tell me WHAT I need but not HOW to organise 30 children using it.
- The interaction types are designed for a digital platform. In a classroom measurement lesson, the primary "interaction type" is physical measurement with real instruments. The digital types (drag_categorise, number_line_scrubber) would supplement, not replace, the hands-on work.

---

### 7. Thinking Lenses

**What was sufficient:**
- Scale, Proportion and Quantity as the primary lens was the right call. The rationale ("1 m = 100 cm encodes a scale factor of 100 that pupils must apply fluently") gave me a genuine teaching angle, not a generic label. I used the "how many times bigger" language in my lesson.
- The question stems were usable: "Which unit of measurement fits best here? Why?" is a question I would actually ask.
- The AI instruction was clear and actionable.

**What was missing:**
- The Structure and Function lens (secondary) felt forced for this content. The rationale about perimeter being "a direct consequence of the side lengths" is technically correct, but the question stems ("How does the shape or arrangement help it do its job?") are Science/DT language, not how a Y3 child thinks about perimeter. I would not use this lens for this cluster.
- No lens specifically for the procedural/conversion aspect of measurement. "Scale, Proportion and Quantity" covers the CONCEPTUAL understanding (why kilo means 1000), but the PROCEDURAL skill (convert mixed units by multiplying and adding) does not fit neatly into any lens. This is not a failure of the lens system -- it is a limitation of applying cross-curricular thinking lenses to procedural mathematics.

---

## Comparison to V7

| Dimension | V7 (Fractions, no CPA) | V8 (Measurement, with CPA) | Change |
|---|---|---|---|
| **Score** | 7.5/10 | 8.5/10 | +1.0 |
| **Differentiation** | Excellent (DL data) | Excellent (DL + CPA) | Same quality, now with resource lists |
| **CPA progression** | Not available -- had to invent entirely | Provided with resources and transition cues | **Major improvement** |
| **Resources** | Extracted from teaching guidance prose | Structured lists per CPA stage | **Major improvement** |
| **Transition criteria** | Not available | Observable behaviour per stage | **Major improvement** |
| **Worked examples** | Had to construct from DL tasks + teaching guidance | Same gap persists | No change |
| **Classroom lesson structure** | Had to expand from 15-min digital profile | Same gap persists | No change |
| **Cross-year prerequisites** | Partially available (curriculum context mentioned Y2) | Weaker -- no Y2 measurement link | Slightly worse for this cluster |

**The +1.0 score increase is almost entirely attributable to RepresentationStage data.** CPA stages gave me:
1. A structured progression through the lesson (concrete -> pictorial -> abstract) with clear descriptions at each stage
2. Specific resource lists I could hand to a TA
3. Transition cues that describe observable readiness behaviours

In V7, I had to invent the CPA progression entirely from professional knowledge. In V8, the graph provided the framework, and I only needed to adapt it to classroom logistics (timings, grouping, TA deployment). This is a genuine step change for a mastery-focused teacher.

---

## Remaining Gaps: What Would Take This to 9/10

### 1. Worked example steps on DifficultyLevel nodes (repeated from V7)

This is still the single highest-impact missing piece. The DL data gives me the problem ("A bag weighs 2 kg 400 g. Another bag weighs 1 kg 750 g. What is their total weight?") and the answer (4 kg 150 g). But the STEPS between problem and answer are what I model on the board:

- Step 1: Convert both to grams. 2 kg 400 g = 2400 g. 1 kg 750 g = 1750 g.
- Step 2: Add. 2400 + 1750 = 4150 g.
- Step 3: Convert back. 4150 g = 4 kg 150 g.

A `worked_example_steps` array on the DifficultyLevel node would eliminate the most time-consuming part of my planning. I flagged this in V7 and it remains my number one request.

### 2. CPA stages for multi-step operations, not just single concepts

The RepresentationStage data describes the CPA for "measuring in mixed units" but not for "adding measurements in mixed units." The addition/subtraction operation has its own CPA journey:
- Concrete: combine physical masses on a balance scale, observe the total
- Pictorial: bar model showing 2 kg 400 g + 1 kg 750 g as joined bars
- Abstract: columnar addition of grams, then convert back to mixed units

This intermediate CPA is absent. The transition cue jumps from "converts between units using the x1000 relationship" (end of Concrete) to "records conversions and calculations on paper" (start of Pictorial) without modelling the bridge for calculation.

### 3. Cross-year prerequisite links

Y2 measurement (measure length in cm, compare lengths, use standard units for mass and capacity) is the primary prerequisite for this Y3 cluster. It is not modelled. The graph has a prerequisite link to columnar addition (an auxiliary skill) but not to the actual measurement concepts from the prior year. This makes the "prior knowledge" section weaker than it should be.

### 4. Multiple example tasks per DifficultyLevel tier

One example per tier establishes the standard. Four would give me a differentiated worksheet. I flagged this in V7 and it remains valid.

### 5. Estimated teaching time on clusters

"None lessons (~None weeks)" is a null value that should be populated. For planning a half-term, I need to know how many lessons each cluster requires. This cluster (2 concepts, introduction type) needs approximately 3-4 lessons. The graph should state this.

---

## Specific Data Quality Issues

| Issue | Location | Severity |
|---|---|---|
| "Estimated teaching time: None lessons (~None weeks)" | Cluster metadata | Medium -- planning requires this |
| "Year group: Y3 ... (None)" | Cluster overview | Low -- cosmetic, but looks unfinished |
| Second thinking lens question stems are Science-oriented, not Maths | Structure and Function lens | Low -- I would simply ignore this lens |
| Pictorial resource list names "scale-reading worksheets" that do not exist | C030 RepresentationStage | Low -- minor frustration |

---

## Final Verdict

### What improved since V7

The RepresentationStage (CPA) data is the clear winner. For a mastery-focused teacher, CPA progression is not optional -- it is the skeleton of every lesson. In V7, I had to build the entire CPA framework from my own training and experience. In V8, the graph gave me:

- Concrete activities with specific resources
- Pictorial representations with appropriate models (bar models, number lines)
- Abstract targets
- Transition cues describing observable child behaviour

This is the difference between "the graph gives me the WHAT to teach" (V7) and "the graph gives me the WHAT and the HOW" (V8). For primary maths, CPA is the HOW.

### What still needs work

The worked example gap persists. DL tasks give me problems and answers. CPA stages give me representations. But the step-by-step procedure that connects problem to answer through the correct representation is still mine to construct. Closing this gap would take the score from 8.5 to 9.0.

The classroom lesson structure gap also persists. The pedagogy profile models 15-min digital sessions. A parallel model for 45-60 minute classroom lessons with guidance on phase timings, concrete resource deployment, and TA roles would bring the graph closer to scheme-of-work quality.

### Score: 8.5 / 10

Up from 7.5 in V7. The RepresentationStage data accounts for nearly all of the improvement. DifficultyLevels remain excellent. The combination of DL (what to assess at each tier) + CPA (how to represent at each stage) gives me a differentiation model that would have taken me 45 minutes to build from scratch. The graph gave it to me in seconds.

This is now comparable to a published scheme's teacher guide for data richness, though it lacks the visual assets (slides, worksheets, manipulative templates) that published schemes include. The data is there; the rendering layer is not. That is a solvable problem.
