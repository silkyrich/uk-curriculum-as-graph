# V6 Teacher Review: Year 3 Curriculum Graph — Can Claude TEACH From This?

**Reviewer:** Ms Rachel Chen, Year 3 class teacher, 9 years' experience
**School:** Two-form entry primary, Bristol
**Date:** 2026-02-23
**Central question:** If Claude had ONLY this graph data, could it sit with a Year 3 child and actually teach them?

---

## 1. Subject-by-Subject Evaluation

Rating scale: 1 = impossible, 5 = could attempt with significant gaps, 10 = could teach confidently

### English

| Domain | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|--------|-------|----------|-----------|-----------------|---------|-------|
| Spoken Language (D001) | 3 | 4 | 2 | 5 | 6 | Good misconceptions data but no model dialogues. Claude can't demonstrate spoken language. |
| Reading - Word Reading (D002) | 6 | 5 | 3 | 7 | 7 | Strong morphology content. Misconceptions excellent. No graded word lists. |
| Reading - Comprehension (D003) | 5 | 4 | 3 | 6 | 8 | Rich concept descriptions but no actual texts to work with. Cross-domain links strong. |
| Writing - Spelling (D004) | 6 | 5 | 3 | 7 | 5 | Good rule explanations. No graded spelling sequences or practice progressions. |
| Writing - Handwriting (D005) | 1 | 1 | 1 | 2 | 2 | Graph cannot model handwriting. Fundamentally physical skill. |
| Writing - Composition (D006) | 5 | 4 | 3 | 5 | 8 | Strong cross-domain reading-to-writing links. No model texts or writing frames. |
| Writing - VGP (D007) | 6 | 5 | 3 | 7 | 6 | Grammar rules well-expressed. Assessment codes map well. No graduated exercises. |

**English average: 4.6 / 10**

### Mathematics

| Domain | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|--------|-------|----------|-----------|-----------------|---------|-------|
| Place Value (D001) | 7 | 6 | 4 | 8 | 8 | KEYSTONE marked. CPA guidance included. Misconceptions superb. No worked examples. |
| Addition & Subtraction (D002) | 7 | 6 | 4 | 8 | 7 | KEYSTONE on columnar addition. Step-by-step CPA guidance. No graded problem sets. |
| Multiplication & Division (D003) | 7 | 6 | 4 | 8 | 8 | Doubling chain (2s-4s-8s) explicitly modelled. Cross-domain links excellent. |
| Fractions (D004) | 6 | 5 | 3 | 7 | 7 | KEYSTONE on unit fractions. Good conceptual guidance. No visual fraction models. |
| Measurement (D005) | 5 | 4 | 3 | 6 | 7 | Practical contexts described well. Can't demonstrate physical instruments. |
| Geometry (D006) | 4 | 3 | 3 | 6 | 6 | Angle concepts well-described. Can't model physical manipulation of shapes. |
| Statistics (D007) | 5 | 4 | 3 | 6 | 6 | Scaled bar charts described. No example datasets or charts to work with. |

**Mathematics average: 5.6 / 10**

### Science

| Domain | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|--------|-------|----------|-----------|-----------------|---------|-------|
| Working Scientifically (D001) | 5 | 4 | 3 | 5 | 7 | Process skills well-described. Content vehicles add investigation context. Can't do the experiments. |
| Plants (D002) | 5 | 4 | 3 | 6 | 6 | Good structure-function teaching guidance. No images/diagrams. |
| Animals inc. Humans (D003) | 5 | 4 | 3 | 6 | 5 | Digestive system, skeleton well-described. Can't use physical models. |
| Rocks (D004) | 4 | 3 | 2 | 5 | 5 | Classification described but no actual rock samples or images. |
| Light (D005) | 5 | 4 | 3 | 6 | 5 | Concepts clear. Misconceptions (light travels FROM eyes) well-captured. |
| Forces & Magnets (D006) | 5 | 4 | 3 | 6 | 7 | Friction investigation vehicle adds practical context. Maths cross-link valuable. |

**Science average: 4.7 / 10**

### History

| Domain | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|--------|-------|----------|-----------|-----------------|---------|-------|
| British History (D002) | 5 | 4 | 3 | 4 | 6 | Content vehicles rich (6 packs). Sources named. Can't show actual artefacts. |
| World History (D003) | 5 | 4 | 3 | 4 | 5 | Good coverage of civilisations. Multiple vehicles with key figures and sources. |
| Historical Enquiry (D004) | 4 | 3 | 2 | 4 | 7 | Disciplinary concepts (cause, significance, evidence) well-defined. No example enquiry sequences. |

**History average: 4.1 / 10**

### Geography

| Domain | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|--------|-------|----------|-----------|-----------------|---------|-------|
| Locational Knowledge (D001) | 4 | 3 | 2 | 4 | 6 | Concepts clear. No actual maps, coordinates, or interactive geography. |
| Place Knowledge (D002) | 3 | 3 | 2 | 3 | 5 | Single concept, very broad. No specific regional data to teach from. |
| Human & Physical (D003) | 4 | 3 | 2 | 5 | 6 | Good conceptual framework. No case study data to work with. |
| Geographical Skills (D004) | 3 | 2 | 2 | 3 | 5 | OS maps fundamentally need physical/visual resources. |

**Geography average: 3.4 / 10**

### Foundation Subjects

| Subject | Model | Scaffold | Hand Over | Respond to Error | Connect | Notes |
|---------|-------|----------|-----------|-----------------|---------|-------|
| Art & Design | 2 | 2 | 1 | 2 | 3 | Fundamentally visual/practical. Graph describes concepts but can't model technique. |
| Music | 2 | 2 | 1 | 2 | 3 | Aural/performance subject. Graph can't model sound or rhythm. |
| D&T | 2 | 2 | 1 | 2 | 3 | Making subject. Graph describes design/make/evaluate cycle but can't model making. |
| Computing | 4 | 3 | 2 | 4 | 5 | Algorithm concepts teachable. Programming needs hands-on. |
| Languages | 3 | 3 | 2 | 3 | 4 | Listening/speaking framework good. No target language content. |
| PE | 1 | 1 | 1 | 1 | 2 | Entirely physical. Graph irrelevant for direct teaching. |

**Foundation average: 2.5 / 10**

### Overall Summary Table

| Subject | Model | Scaffold | Hand Over | Respond to Error | Connect | AVERAGE |
|---------|-------|----------|-----------|-----------------|---------|---------|
| English | 4.6 | 4.0 | 2.6 | 5.6 | 6.0 | **4.6** |
| Mathematics | 5.9 | 4.9 | 3.4 | 7.0 | 7.0 | **5.6** |
| Science | 4.8 | 3.8 | 2.8 | 5.7 | 5.8 | **4.6** |
| History | 4.7 | 3.7 | 2.7 | 4.0 | 6.0 | **4.2** |
| Geography | 3.5 | 2.8 | 2.0 | 3.8 | 5.5 | **3.5** |
| Foundation | 2.3 | 2.2 | 1.3 | 2.3 | 3.3 | **2.3** |
| **OVERALL** | **4.3** | **3.6** | **2.5** | **4.7** | **5.6** | **4.1** |

---

## 2. Cross-Subject Patterns

### What's consistently STRONG

**A. Error diagnosis (avg 4.7/10 — the graph's best dimension)**

The `common_misconceptions` property on every concept is genuinely excellent. For Maths in particular, the misconceptions data is teacher-quality:

> "Pupils frequently subtract the smaller digit from the larger regardless of position — computing 352 – 7 as 355 (taking 5 from 7 gives 2, putting 2 in the ones place)"

That's not a textbook platitude. That's what I see in my marking every single day. If Claude reads that misconception data and the child writes 355 for 352 - 7, Claude could actually diagnose: "I think you might have subtracted the smaller number from the bigger number in the ones column. Let's look at that again..." This is powerful.

**B. Cross-domain connections (avg 5.6/10 — the graph's strongest dimension)**

The `CO_TEACHES` relationships and cross-domain links are genuinely useful for teaching. The link from `EN-Y3-C020` (fairy stories, myths and legends) to `EN-Y3-C048` (narrative elements) with the rationale "provides structural templates for narrative elements" is exactly how I plan my English teaching. The reading-to-writing links are the backbone of my literacy curriculum.

The maths cross-domain links are equally strong: place value feeding into columnar addition, counting in multiples feeding into times tables, place value extending into tenths. Claude could use these to say "Remember when we learned about hundreds, tens and ones? Columnar addition uses those same columns..."

**C. Prerequisite chains**

The prerequisite relationships give Claude a genuine map of "what needs to come before what." The chain `MA-Y3-C007 (place value) → MA-Y3-C008 (partitioning) → MA-Y3-C009 (comparing)` is pedagogically correct. A good AI tutor could use these chains to diagnose *where* understanding broke down: if a child can't compare 465 and 456, Claude could trace back to ask whether they understand what each digit is worth.

### What's consistently WEAK

**A. Handover criteria (avg 2.5/10 — the graph's worst dimension)**

The graph tells Claude WHAT to teach and WHAT errors to look for, but it almost never tells Claude WHEN THE CHILD IS READY TO TRY ALONE. There is no concept of "success at this level looks like..." expressed as observable child behaviour.

The `success_criteria` in content vehicles are a start (e.g., "Identify the independent, dependent, and controlled variables") but these are assessment endpoints, not handover signals. In my classroom, I'd say "You're ready to try on your own when you can explain to me why we need to keep the ramp height the same." That mid-lesson, micro-decision about handover is completely absent.

**B. Difficulty progression WITHIN concepts (avg 3.6/10)**

Each concept has a single `complexity` rating (1-4) but no internal gradient. Take `MA-Y3-C014 — Formal columnar addition`. The teaching guidance mentions CPA progression (concrete → pictorial → abstract) but there are no defined sub-levels:

- Level 1: HTU + TU, no carrying
- Level 2: HTU + HTU, carrying in ones only
- Level 3: HTU + HTU, carrying in ones and tens
- Level 4: HTU + HTU with zeros, multiple carries

Without this progression, Claude can't START EASY when a child is struggling. It has one undifferentiated blob of "columnar addition" and must generate its own difficulty gradient from scratch.

**C. No exemplar content (avg 3.6/10)**

The graph describes what Claude should teach but provides almost no actual teaching materials:

- No model texts for English (the graph says "use fairy stories, myths and legends" but doesn't provide any)
- No worked examples for Maths (the graph describes the grid method but doesn't show one being worked through step by step)
- No images, diagrams, or visual representations for Science
- No primary sources for History (the graph names "Vindolanda tablets" and "Sutton Hoo helmet" but doesn't provide them)

Claude would have to generate ALL content from its own training data, using the graph only as a navigation aid. This is a curriculum map used as a sat-nav — it tells you where to go but doesn't build the road.

**D. No model of how learning SOUNDS**

The biggest single gap: the graph contains no examples of what good teaching dialogue looks like. It tells Claude the concepts, the misconceptions, the teaching guidance — but it never models:

- What a think-aloud sounds like: "Let me think about 347 + 286. I'm going to start with the ones column. 7 + 6 = 13. That's more than 9, so I need to carry the 1 ten..."
- What scaffolding questions sound like: "What's the value of the 4 in 347? ...Good. So how many tens is that?"
- What error correction sounds like: "I noticed you wrote 523 for 347 + 286. Let me ask you — what did you get when you added the tens? Can you show me?"

---

## 3. The Expressive Framework: What the Graph Needs

To move from curriculum map to teaching system, the graph needs five new data structures:

### 3.1 Difficulty Sub-Levels (`DifficultyLevel` nodes or properties)

**Schema:**
```
(:Concept)-[:HAS_DIFFICULTY_LEVEL]->(:DifficultyLevel {
  level_id: "MA-Y3-C014-DL003",
  level_number: 3,       // 1 = entry, 5 = mastery
  description: "HTU + HTU with carrying in ones and tens",
  example_problem: "347 + 286",
  expected_correct_response: "633",
  entry_check: "Can the child do HTU + HTU with carrying in ones only (Level 2)?",
  handover_signal: "Child completes 3 consecutive problems at this level without error",
  common_errors_at_level: ["Forgets to add carried digit in tens column", "Carries from ones but not tens"],
  scaffold_if_stuck: "Cover the hundreds column. Can you add just the tens and ones?"
})
```

**Why:** This is the single most impactful addition. It gives Claude a LADDER within each concept. Currently the graph has 1,278 concepts but no rungs between "can't do it" and "has mastered it". With 3-5 difficulty levels per concept, Claude could:
- Start at the child's level
- Detect when to move up
- Drop back down when the child struggles
- Know when to hand over to independent practice

### 3.2 Teaching Moves (`TeachingMove` nodes)

**Schema:**
```
(:DifficultyLevel)-[:HAS_TEACHING_MOVE]->(:TeachingMove {
  move_id: "MA-Y3-C014-DL003-TM001",
  move_type: "model",    // model | scaffold_question | error_correction | check_understanding | handover
  trigger: "Child sees HTU+HTU with double carry for first time",
  dialogue_template: "Watch me do this one first. I'm going to add {num1} and {num2}. I always start in the ones column. {ones_digit1} + {ones_digit2} = {ones_sum}. That's more than 9, so I write the {ones_unit} and carry the {tens_carry}...",
  variables: ["num1", "num2", "ones_digit1", "ones_digit2", ...],
  age_register: "Y3",    // controls vocabulary and sentence complexity
  think_aloud: true       // whether Claude should verbalise its reasoning
})
```

**Why:** This encodes the CRAFT of teaching. A teaching move is the smallest unit of pedagogical action: "model this", "ask this check question", "correct this error in this way". Currently the graph has `teaching_guidance` as a blob of text on each concept. Teaching moves break this into individual, triggerable actions.

### 3.3 Error-Response Pairs (`ErrorPattern` nodes)

**Schema:**
```
(:Concept)-[:HAS_ERROR_PATTERN]->(:ErrorPattern {
  error_id: "MA-Y3-C014-EP003",
  child_response_pattern: "Answer is exactly 100 too small",
  diagnosis: "Child forgot to add carried digit in the tens column",
  diagnostic_question: "Can you show me what you did in the tens column? Did you remember to add the little number you carried?",
  correction_move: "Let me show you just the tens column part. We had {tens_sum} from the tens digits, PLUS {carried} that we carried. {tens_sum} + {carried} = {corrected_tens}.",
  severity: "procedural",  // conceptual | procedural | careless
  follow_up: "Try this one: {easier_similar_problem}. Talk me through each step as you go."
})
```

**Why:** The existing `common_misconceptions` text is excellent but unstructured. Claude has to parse a paragraph to extract what the child did wrong and why. Error-response pairs make each misconception ACTIONABLE: if the child does X, say Y, then give them Z to try.

### 3.4 Handover Criteria (`HandoverCriteria` on DifficultyLevel or Cluster)

**Schema:**
```
(:ConceptCluster)-[:HAS_HANDOVER_CRITERIA]->(:HandoverCriteria {
  criteria_id: "MA-Y3-D002-CL002-HC001",
  observable_behaviour: "Child correctly completes columnar addition with carrying, explains their working using place value language",
  independence_indicators: [
    "Completes problem without prompting",
    "Self-corrects using estimation check",
    "Can explain WHY they carried"
  ],
  not_ready_indicators: [
    "Still needs to be reminded to start from ones",
    "Cannot explain what carrying means",
    "Correct answers but no understanding of place value"
  ],
  independent_practice_type: "graduated_problem_set",  // what to give them next
  success_threshold: "3 consecutive correct at highest difficulty level with verbal explanation"
})
```

**Why:** This tells Claude the difference between a child who can DO the procedure and a child who UNDERSTANDS it. In my classroom, I'd never hand over to independent practice just because a child got three right — I'd also check they can explain what they're doing. Currently the graph has no way to express this distinction.

### 3.5 Worked Example Sequences (`WorkedExample` nodes)

**Schema:**
```
(:DifficultyLevel)-[:HAS_WORKED_EXAMPLE]->(:WorkedExample {
  example_id: "MA-Y3-C014-DL003-WE001",
  problem: "347 + 286",
  steps: [
    {"step": 1, "action": "Set up columns", "display": "  347\n+ 286\n-----", "say": "I'll write 347 on top and 286 underneath, lining up the ones, tens and hundreds."},
    {"step": 2, "action": "Add ones", "display": "7 + 6 = 13", "say": "Starting with the ones: 7 plus 6 is 13. 13 is 1 ten and 3 ones. I write 3 in the ones answer and carry the 1 ten."},
    {"step": 3, "action": "Add tens", "display": "4 + 8 + 1 = 13", "say": "Now the tens: 4 tens plus 8 tens is 12 tens, plus the 1 ten I carried makes 13 tens. 13 tens is 1 hundred and 3 tens. I write 3 in the tens and carry the 1 hundred."},
    {"step": 4, "action": "Add hundreds", "display": "3 + 2 + 1 = 6", "say": "Finally the hundreds: 3 hundreds plus 2 hundreds is 5, plus the 1 I carried makes 6 hundreds."},
    {"step": 5, "action": "Check", "display": "347 + 286 = 633", "say": "My answer is 633. Let me check: 350 + 290 is about 640. 633 is close, so that looks right."}
  ],
  variation_prompts: ["Now you try: 258 + 374", "This time, talk me through each step"],
  error_trap: "If child says 533 (forgetting carried digit in hundreds), go to EP003"
})
```

**Why:** THIS is what teaching looks like. Not "teach columnar addition using CPA progression" but literally "say this, show this, then have the child do this." The graph currently describes teaching at the level of a scheme of work. Worked examples describe it at the level of a classroom interaction.

---

## 4. Three Worked Examples: Current vs. Needed

### 4.1 Maths: Columnar Addition (347 + 286)

**CURRENTLY, Claude teaching from this graph would say:**

> "Today we're going to learn about formal columnar addition. This means adding numbers by writing them in columns — ones under ones, tens under tens, hundreds under hundreds. When a column adds up to more than 9, we carry the extra into the next column. Let's try 347 + 286. Can you set up the columns?"

This is a DESCRIPTION of the method. It's what you'd get from a textbook. Claude knows the concept (from teaching guidance), the misconception (from common_misconceptions), and the vocabulary (from key_vocabulary). But it's not TEACHING. It's telling.

**WITH the expressive framework, Claude would say:**

> "I'm going to show you how I add these big numbers. Watch what I do and tell me if you notice a pattern.
>
> *[Shows: 347 + 286]*
>
> I always start on the right side. That's the ones column. 7 and 6... I know 7 + 6 = 13. But 13 is too big for one column! 13 is the same as 1 ten and 3 ones. So I write 3 in the ones answer... and I carry this little 1 up to the tens column. Can you see it?
>
> Now the tens. 4 tens and 8 tens makes... 12 tens. But wait — I need to add the 1 I carried! 12 + 1 = 13 tens. Same thing — too big. 13 tens = 1 hundred and 3 tens. Write 3, carry 1.
>
> Last one: hundreds. 3 + 2 = 5, plus my carried 1 = 6. Write 6.
>
> My answer is 633. Quick check: 350 + 300 is about 650. 633 is close. That makes sense.
>
> Now — your turn. Try 258 + 374. Talk me through each step the way I just did. I'll listen."

Then, if the child gets 522 (forgetting the carried ten), Claude would match to ErrorPattern EP003 and respond:

> "Hmm, let me look at your tens column. You wrote 5 + 7 = 12, so you wrote 2 and carried 1. But did you add the 1 you carried from the ones column? Let's look at that step again together."

### 4.2 English: Drawing Inferences (EN-Y3-C027)

**CURRENTLY, Claude would say:**

> "Today we're going to practise drawing inferences. An inference is when you read between the lines — you use clues in the text and what you already know to work out something the author hasn't said directly. For example, if the text says a character 'slammed the door and threw their bag on the floor', we can infer they are angry. Let's look at this passage and see what inferences we can draw."

But Claude has no passage to look at. The graph says "use the PEE structure" and "start with character feelings and motivations" but provides no text.

**WITH the expressive framework, Claude would have:**

> *[Presents a short passage from a linked text corpus, graded for Y3 reading level]*
>
> "Listen to this bit: 'Maya pushed her cereal around the bowl. She kept glancing at the clock on the wall.'
>
> I'm going to show you how I read between the lines. The author doesn't SAY Maya is worried about being late. But look at the clues: she's not eating her cereal — she's pushing it around. And she keeps looking at the clock. Why would someone keep looking at a clock? Usually because they're worried about time.
>
> So my inference is: Maya is worried about being late for something. My evidence is the clock-watching and the not eating.
>
> Now you try. Read the next paragraph: 'On the bus, Maya sat at the back and stared out the window. She didn't talk to Anya, even when Anya said hello.'
>
> What can you infer about how Maya is feeling? Remember — Point, Evidence, Explain. What do you think? What's your evidence from the text? Why does that evidence support your inference?"

The missing piece: the graph has no TEXT CORPUS, no graded passages, no model inference chains. Claude would need to generate all of this from scratch.

### 4.3 Science: Plant Requirements (SC-KS2-C012)

**CURRENTLY, Claude would say:**

> "Plants need air, light, water, nutrients from the soil, and room to grow. They make their own food through photosynthesis — they use light to turn water and carbon dioxide into food. This is different from animals, which have to eat food. Common misconception: plants do NOT get their food from the soil. The soil provides minerals, but the plant makes its own food in its leaves using sunlight."

This is factually correct and addresses the key misconception. But it's TELLING, not TEACHING.

**WITH the expressive framework, Claude would say:**

> "Here's a puzzle for you. I've got two plants. One I put in a cupboard with no light. One I put on the windowsill. I watered them both the same. After two weeks, the cupboard plant is pale and droopy. The window plant is green and healthy.
>
> Why do you think the cupboard plant isn't doing well? What's different?
>
> *[Child answers: 'Because it has no light']*
>
> Good — but WHY does it need light? Here's what most people think: they think the soil feeds the plant, like food feeds us. But actually... *[pause]* ...the plant makes its OWN food. In its leaves. And it needs LIGHT to do it. It's like the plant has a little kitchen in every leaf, and the light is the cooker. No light, no cooking, no food.
>
> The soil gives the plant water and minerals — like vitamins. But the actual food? The plant builds it itself from light and air.
>
> So here's my question: if I gave the cupboard plant lots of fertiliser but still no light, would it grow? Think carefully..."

This requires the content vehicle (SC-KS2-CV002 Plant Growth Enquiry) to actually contain the step-by-step investigation prompts, the predicted child responses, and the Socratic questioning sequence — not just the equipment list and success criteria.

---

## 5. Overall Verdict

### How far is the graph from being a teaching system?

**The graph is currently a 4.1/10 as a teaching system. It is an excellent 8/10 as a curriculum map.**

The distinction matters enormously. What the graph does brilliantly:
- Maps the WHAT of Y3 teaching across all subjects
- Expresses CONNECTIONS between concepts (prerequisites, co-teaches, cross-domain)
- Identifies WHERE children go wrong (misconceptions)
- Organises concepts into TEACHABLE CLUSTERS with sequencing
- Provides COGNITIVE FRAMING through thinking lenses
- Links to ASSESSMENT endpoints through content domain codes
- Gives Claude NAVIGATION — it knows where it is in the curriculum and where to go next

What the graph fundamentally lacks for teaching:
- **No difficulty ladder within concepts** — Claude can't start easy and build up
- **No model of what teaching SOUNDS LIKE** — no dialogue templates, no think-alouds
- **No content to teach WITH** — no texts, no worked examples, no images, no datasets
- **No handover criteria** — Claude doesn't know when the child is ready to try alone
- **No error-response pairs** — misconceptions are identified but not made actionable

### The path from 4/10 to 8/10

The graph needs three layers added in this priority order:

1. **Difficulty Sub-Levels** (highest impact, ~3,000-5,000 nodes for Maths and English alone). This is the single most important addition. Without it, Claude has a flat landscape with no elevation change — it can't adapt to the child.

2. **Worked Examples with Teaching Moves** (highest teaching fidelity, ~1,000-2,000 nodes for core subjects). This encodes what teaching actually sounds and looks like. It transforms Claude from "an AI that knows about columnar addition" to "an AI that can TEACH columnar addition."

3. **Error-Response Pairs** (highest diagnostic value, ~500-1,000 nodes for Maths, ~300-500 for English). The misconception data is already excellent — this layer makes it machine-actionable.

### The honest assessment

After nine years of teaching Year 3, here's what I'd say: the graph as it stands would help Claude be an excellent REVISION PARTNER — it could quiz children, correct errors using the misconception data, and make connections between topics. It would be a good EXPLANATION ENGINE — it could explain concepts clearly because the teaching guidance is well-written.

But it could not yet SIT WITH A CHILD AND TEACH. Teaching is not explaining. Teaching is modelling thinking step by step, watching the child's face (or response), adjusting in real time, knowing when to push and when to pull back, and gradually releasing control until the child can do it alone. The graph maps the territory. The territory itself — the moment-by-moment craft of teaching — still needs to be built.

The foundations are strong. The architecture is right. The misconception data alone is worth its weight in gold. But the last mile — from "knows what to teach" to "can teach it" — is the hardest mile, and it's still ahead.

---

## Appendix: Data Quality Notes

### Positive observations
- Teaching guidance text is consistently high-quality and practitioner-informed
- Misconception data matches my real classroom experience (especially Maths)
- Cross-domain links are pedagogically sound (reading-to-writing, counting-to-tables)
- Content vehicles for History add genuine richness (sources, perspectives, key figures)
- KEYSTONE markers correctly identify the gateway concepts (place value, unit fractions, columnar addition)
- Complexity ratings are sensible and consistent within subjects

### Issues found
- **Prerequisite anomaly in EN-Y3 Spoken Language**: The prerequisites map KS1 phonics concepts (phoneme, grapheme, GPC, blending, segmenting) to spoken language concepts (active listening, questioning, etc.). These are arbitrary — phonics is not a genuine prerequisite for spoken language. The spoken language prerequisites should trace from KS1 spoken language/oracy concepts, not from decoding.
- **Science domains are KS2-wide, not Y3-specific**: The Science concepts cover the entire KS2 range (including upper KS2 concepts like circulatory system, evolution). A Y3 child would not encounter SC-KS2-C060 (Circulatory System, complexity 4, teaching weight 5). The context file doesn't filter to Y3-appropriate content, which would confuse Claude about what to teach when.
- **Geography and History concepts are very broad**: HI-KS2-C005 (British Historical Periods: Prehistoric to Medieval) is a SINGLE concept spanning the entire KS2 British history curriculum. This is too coarse for teaching — Claude can't scaffold through "the Stone Age" vs "the Iron Age" vs "the Romans" because they're all one concept node.
- **Foundation subjects are skeletal**: Art, Music, D&T, PE have minimal concept detail compared to core subjects. This is understandable given their practical nature but means Claude has almost nothing to work with.
- **Some Thinking Lens rationales are template-duplicated**: Multiple clusters across different subjects have identical rationale text for the same lens (e.g., "Proportional relationships follow predictable patterns..."). The V5 review flagged this — it hasn't been fully addressed.

---

*Report written 2026-02-23 by Ms Rachel Chen (simulated Y3 teacher persona)*
