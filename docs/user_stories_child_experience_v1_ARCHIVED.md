# Child-Perspective User Stories: UK Educational Platform

*Written from the perspective of the child using the product. Each story shows the exact text on screen, the AI voice adapting to age, and the pedagogical principles operating in the background — not described but demonstrated.*

---

## 1. The Very First Number Line
**Year group:** Y1 · **Age:** 5–6 · **Subject:** Mathematics — Counting / Place Value
**Scenario:** First encounter with the platform. A child who has never used it before opens it for the first time. The AI does not test. It plays.
**Pedagogical principles:** Productive failure (mild), metacognitive prompts (accessible), effort attribution, semi-random delight

### Setting
A Tuesday evening, just after bath time. Amelie, age 5, is on a shared family iPad at the kitchen table. Her mum set up the account earlier. Amelie opens the app for the first time. She can read simple words. She taps things confidently.

### The feed

**AI message card**
> Hi Amelie!
>
> I'm going to show you some things.
> Some will be easy. Some will be a bit tricky.
> That's fine. Let's go!

*[Large illustrated character on screen — a small round creature with curious eyes. It waves.]*

---

**Challenge card**
*[Colourful number line from 0 to 10. Each number sits on a stepping stone crossing a river. A frog sits on stepping stone 3.]*

> Where should the frog jump next?
>
> Tap the stepping stone!

*[Interactive: all stepping stones are tappable. No labels suggesting right or wrong.]*

*[Amelie taps 7. A ripple animation plays. The frog leaps to 7. A pause.]*

**AI message card**
> Ooh — the frog made it!
> You picked 7.
> The frog was on 3. How many jumps was that?
> *[Three fingers appear on screen, counting up visually: 4, 5, 6, 7]*
> Four jumps!

---

**AI message card**
> Let's try the other way.
> What if the frog wants to go BACK?
> Back means smaller numbers — closer to zero.

---

**Challenge card**
*[Same river. Frog is now on stepping stone 8.]*

> The frog wants to get home.
> Home is on stepping stone 2.
> Tap where the frog should go FIRST.

*[Amelie taps 5. Correct direction. The frog hops to 5.]*

> Yes! That's going backwards — getting smaller.
> Tap again. Keep going to 2!

*[She taps 4, 3, 2. The frog hops home. Lily pads bloom.]*

---

**Delight card**
*[The river fills with animated frogs, all jumping in different directions. A sound plays — comedic frog croaking in rhythm. The frog at home does a little dance. After 4 seconds it fades and the feed continues.]*

---

**AI message card**
> Amelie — you kept going even when it was a bit confusing.
> That's the thing about numbers. They go both ways.
> Same idea tomorrow. Different animals, probably.

### What happens next
At the next session, the AI presents a number track with a different character (a snail, a ladybird) moving in either direction. It has logged that Amelie needed the directional framing ("back means smaller") and will revisit this before introducing any subtraction language.

### Parent notification
**Triggered because:** First session complete. Parent notifications fire more frequently at Y1–Y2. This one is content-rich to prompt a conversation.

> **From the learning app — Amelie's first session**
>
> Amelie just spent 8 minutes on the app for the first time.
>
> She worked on number lines — moving a frog forwards and backwards between 0 and 10. When the frog needed to "go home," she figured out she needed to go in the opposite direction. That's the beginning of understanding that subtraction is about direction, not just "taking away."
>
> Something to try tonight: point at house numbers on your street and ask her which way she'd walk to get to a smaller number. She'll probably get it straight away.

---

## 2. The Sound in the Middle
**Year group:** Y1–Y2 · **Age:** 6–7 · **Subject:** English — Phonics / Early Reading
**Scenario:** A child encounters a CVC word with a vowel sound they've been confusing. The AI notices the pattern and addresses it directly, without naming it as an error.
**Pedagogical principles:** Productive failure, scaffolded hints, effort attribution, self-comparative feedback (gentle version)

### Setting
A Saturday morning. Reuben, age 6, is on his own tablet in his bedroom. He has been using the platform for three weeks. He can read many CVC words but consistently confuses short /e/ and short /i/.

### The feed

**Challenge card**
*[Large, clean image of a hen sitting on a nest. No text other than the challenge.]*

> What's this?
> Spell it by tapping the sounds.
>
> *[Letter tiles: h · e · n · i · a · t (in shuffled order)]*

*[Reuben taps: h — i — n]*

**AI message card**
> Hmm. H-I-N.
> Say that out loud. Does it sound like the picture?
> *[Audio plays: "hin" — the AI models the word as he spelled it, slightly exaggerated.]*
> *[Then audio plays: "hen" — the correct word, clearly.]*
> Which sounds more like the picture?

*[Reuben listens. He taps the audio button again. Then taps 'e'.]*

> Yes — HEN. You heard it.
> That middle sound is sneaky. A lot of people mix those two up.
> You just figured it out by listening harder. That's the move.

---

**Challenge card**
*[Image of a bed.]*

> Spell this one.
> *[Tiles: b · e · d · i · a · u]*

*[Reuben immediately taps: b — e — d.]*

**AI message card**
> Got it straight away.
> Last week you were trying that one a few times. Not this time.

---

**Challenge card**
*[Image of a pin.]*

> What about this?
> *[Tiles: p · i · n · e · a · t]*

*[Reuben pauses. He taps 'e', then quickly changes to 'i'. Types: p — i — n.]*

**AI message card**
> PIN — yes.
> You started to put 'e' there and changed your mind. Good catch.
> Your ears are working hard today.

---

**Explanation card**
*[Appears after the three attempts — this is the post-failure explanation.]*

> Here's something worth knowing about those two sounds.
>
> Short /e/ — like in **hen, bed, leg, red**
> Say "eh" — mouth a bit open, like you're surprised.
>
> Short /i/ — like in **pin, big, sit, him**
> Say "ih" — mouth almost closed.
>
> *[Animated mouth diagrams show the shape for each.]*
>
> They live very close to each other. Even grown-ups mix them up in new words.

### What happens next
The AI flags the /e/ vs /i/ confusion in the learner model. Over the next four sessions, it will interleave words with both sounds, always placing them close together so the contrast stays sharp. It will not mention this plan to Reuben.

### Parent notification
**Triggered because:** A specific, teachable moment happened that parents can easily reinforce.

> **From the learning app — Reuben's phonics session**
>
> Reuben spent 12 minutes today on spelling short vowel sounds. He's been mixing up the 'e' sound (as in **hen**) and the 'i' sound (as in **pin**) — this is one of the most common confusions at this stage, and completely normal.
>
> Today he caught himself mid-word and self-corrected on **pin**. That's a real skill — it means his ear is starting to notice the difference.
>
> If you're reading together this week, you could point to a word like "bed" or "bit" and ask: "which sound is in the middle there?" Just casually. No pressure. It helps the distinction stick.

---

## 3. What Do You Notice?
**Year group:** Y2 · **Age:** 6–7 · **Subject:** Science — Observation (Working Scientifically, KS1)
**Scenario:** The platform introduces scientific observation through a simple "what do you notice?" structure before any vocabulary is introduced. The child generates their own observations before the AI names anything.
**Pedagogical principles:** Productive failure (observing without labels), metacognitive prompts, effort attribution, explanation after attempt

### Setting
A weekday after school. Sofia, age 7, is at home on a family laptop. Her class has been doing a topic on plants. The AI has picked up from her recent sessions that she is confident with naming parts of plants but has not yet engaged with observation-as-process.

### The feed

**AI message card**
> Sofia — here's a photo.
> Don't try to name things yet. Just look.
> I'll ask you what you notice in a second.

*[A close-up photograph of two bean seedlings in pots, side by side. One is taller, greener, with more leaves. One is short and pale yellow.]*

---

**Challenge card**
> What do you notice about these two plants?
> Tap the things that are different.
>
> *[Free-response text field and a list of features the child can tap: colour · height · leaf size · number of leaves · stem thickness · other]*

*[Sofia taps: colour, height, number of leaves. She types in "other": "one looks sick"]*

**AI message card**
> "One looks sick" — that's a brilliant observation.
> Scientists say exactly that kind of thing. They notice things look wrong before they know why.
>
> You spotted: colour, height, leaves, and that something seems off.
> That's four observations. Let's think about what might explain it.

---

**Challenge card**
> These two plants started from the same seeds, in the same soil, on the same day.
>
> What's the most likely reason one looks different from the other?
>
> *[Four options with small illustrations:]*
> - The tall one was watered more
> - The short one was kept in the dark
> - The tall one is a different type of seed
> - The short one is too cold

*[Sofia picks: "The short one was kept in the dark"]*

**AI message card**
> That's the right idea — and here's something interesting.
> You can't know for certain from this photo alone.
> Scientists can't either. That's why they set up experiments.
>
> But your thinking is good. Plants need light to make their green colour.
> The yellow-ish plant hasn't had much. And look — it's stretched tall trying to reach light.

---

**Explanation card**
> When a plant grows towards light, scientists call it **phototropism**.
>
> Photo = light. Tropism = turning towards something.
>
> The plant that was in the dark used all its energy trying to find light. It grew tall and thin — but it couldn't make the green stuff (chlorophyll) because you need light to do that.
>
> You noticed it looked "sick." That word is pretty close to what's actually happening. It was under stress.

---

**AI message card**
> What you did just now — looking carefully, then guessing a reason — that's exactly what scientists do.
> They call it making a hypothesis.
> You made one. And it was a good one.

### What happens next
The next science session will present a second image — a similar observation task with snails, connecting to animal behaviour. The AI will reference back ("same idea — look first, explain later") to build the metacognitive habit of observation-before-labelling.

### Parent notification
**Triggered because:** Sofia used her own language ("one looks sick") before the scientific vocabulary arrived — a notable moment of genuine thinking worth sharing.

> **From the learning app — Sofia's science session**
>
> Today Sofia looked at photos of two bean plants and had to explain why they looked different. Before we told her anything, she said one "looked sick" — which is actually a pretty accurate scientific observation. The pale, stretched plant was growing in the dark and couldn't produce chlorophyll.
>
> We introduced the word **phototropism** — plants growing towards light. You might see it on your windowsill: houseplants often lean towards windows. Sofia could explain why now.

---

## 4. Three Tables at Once
**Year group:** Y3–Y4 · **Age:** 8–9 · **Subject:** Mathematics — Multiplication, Interleaving
**Scenario:** The AI deliberately mixes 4×, 6×, and 8× tables within a single session and explicitly tells the child why — modelling metacognitive transparency about the learning strategy itself.
**Pedagogical principles:** Interleaving (explicit), metacognitive prompts, self-comparative feedback, effort attribution

### Setting
A Wednesday evening. Marcus, age 8, has been using the platform for two months. He knows his 4× table well. He has seen 6× and 8× but finds them harder. The AI has detected he tends to try rushing to the answer without pausing.

### The feed

**AI message card**
> Marcus — heads up. I'm going to mix three different tables together today.
> 4s, 6s, and 8s — switching between them without warning.
> That's on purpose.
>
> Mixing things up actually helps them stick better than doing one at a time.
> It might feel a bit harder. That's the point.

---

**Challenge card**
> 6 × 7 = ?
>
> *[Number input field. No time pressure shown.]*

*[Marcus types 42. Correct.]*

**AI message card**
> Good. Here's a different one.

---

**Challenge card**
> 4 × 8 = ?

*[Marcus types 32. Correct.]*

---

**Challenge card**
> 8 × 6 = ?

*[Marcus types 42. Incorrect — he carried over the 6×7 answer.]*

**AI message card**
> Not this time. Here's the thing — you just did 6×7 a moment ago, and 6×7 IS 42.
> 8×6 is different. New calculation.
>
> Here's a hint: what's 8×3? Double that.

*[Marcus thinks. Types 48.]*

> Yes — 8×6 = 48. And notice: 6×8 would give you the same answer.
> Multiplication doesn't mind which order you go.

---

**Challenge card**
> 8 × 9 = ?

*[Marcus pauses longer this time. Types 72.]*

**AI message card**
> Right.
> What did you do there? I noticed you took longer.

*[Multiple choice response:]*
> - I counted on my fingers
> - I broke it into 8×10 then took away 8
> - I just remembered it
> - I'm not sure

*[Marcus taps: "I broke it into 8×10 then took away 8"]*

> That's a proper strategy. That's exactly what mathematicians do when they don't just remember something — they build it from something they do know.
> That's worth keeping.

---

**Challenge card**
> 6 × 4 = ?

*[Marcus types 24. Correct.]*

**Challenge card**
> 8 × 7 = ?

*[Marcus types 54. Incorrect.]*

**AI message card**
> Not quite. 8×7 trips a lot of people up.
>
> Try this: you know 8×6 = 48. What's one more group of 8 on top of that?

*[Marcus types 56.]*

> 56. Right. You rebuilt it from 48. Two wrong turns today, but both times you found the answer yourself.

---

**AI message card**
> A few weeks ago you were doing 4s only, and you said the 8s were "too hard."
> Today you did 8×6 and 8×9 and 8×7.
> Different Marcus.

### What happens next
The AI schedules a revisit of 8×7 and 8×6 within the next two sessions — both because they caused errors and because they are historically confusing pairs. The interleaving continues across the next week, with 3× and 7× introduced into the mix.

---

## 5. The Timeline That Came to Life
**Year group:** Y3–Y4 · **Age:** 8–9 · **Subject:** History — Chronological Ordering
**Scenario:** A child is ordering events from Roman Britain on a timeline when a delight card fires mid-sequence — an unexpected interactive animation that breaks the fourth wall briefly before the learning continues.
**Pedagogical principles:** Semi-random delight, metacognitive prompts, effort attribution

### Setting
A Sunday afternoon. Isla, age 9, is using the platform on a laptop. Her class has been studying ancient civilisations. She has been on the platform for 8 minutes and has answered four questions correctly. The delight trigger fires based on a streak of engagement (not correctness — the platform does not track scores, but it does track sustained interaction without distraction signals).

### The feed

**Challenge card**
> Put these events in order — earliest first.
> Drag them into the right position on the timeline.
>
> *[Cards to drag:]*
> - Romans invade Britain (AD 43)
> - Julius Caesar's raids on Britain (55–54 BC)
> - Boudicca's revolt (AD 60/61)
> - Romans leave Britain (AD 410)
> - Hadrian's Wall begins to be built (AD 122)

*[Isla drags them. She puts Caesar's raids first — correct. She places Boudicca after Hadrian's Wall.]*

**AI message card**
> Nearly! You've got the order mostly right.
> One thing — Boudicca was fighting before Hadrian's Wall was built.
>
> Think about it this way: you'd build a big defensive wall AFTER there'd been trouble, not before.
>
> Try swapping those two.

*[Isla swaps them. Correct.]*

---

**Delight card**
*[The timeline suddenly animates. A small Roman soldier marches across the screen left to right. He stops at "AD 43", looks at the camera, shrugs dramatically, and keeps marching. When he reaches "AD 410" he stops, drops his shield, waves goodbye, and walks off the right edge of the screen. A small caption appears: "Alright, that's enough Britain for us." Then the screen returns to normal.]*

*[No text from the AI. No explanation. It just happens, then disappears.]*

---

**AI message card**
> Right. Back to it.
>
> Here's something worth thinking about: you ordered those events without knowing the exact dates for most of them.
> How did you figure it out?

*[Multiple choice:]*
> - I remembered the dates
> - I used clues in the descriptions
> - I guessed
> - I'm not sure

*[Isla taps: "I used clues in the descriptions"]*

> That's historical thinking. Proper historians do exactly that — they read sources for clues about sequence even when dates aren't obvious. You're doing the same thing.

---

**Challenge card**
> If Boudicca revolted in AD 60 and Hadrian's Wall started in AD 122 — how many years apart are those events?

*[Isla types 62. Correct.]*

**AI message card**
> 62 years. That's longer than most people's whole lives in Roman times.
> History involves big gaps of time. Worth keeping that in your head.

### What happens next
The delight moment is not referenced again. It was a punctuation mark, not a reward. In the next session, the AI returns to chronological ordering with a different civilisation (Vikings), referencing what Isla said about "using clues in descriptions" as a transferable strategy.

### Parent notification
Not triggered this session — the session was mid-length and no specific breakthrough moment occurred. Y3–Y4 notifications fire less frequently than Y1–Y2.

---

## 6. The Melting Ice Experiment That Wasn't
**Year group:** Y3–Y4 · **Age:** 9 · **Subject:** Science — Working Scientifically, Productive Failure
**Scenario:** A child is asked to design an experiment before being taught how. They produce an incomplete design — missing a control variable. The explanation arrives only after they've tried and encountered the gap themselves.
**Pedagogical principles:** Productive failure (central), metacognitive prompts, scaffolded hints, explanation after attempt

### Setting
An evening session. Callum, age 9, is on a tablet at the kitchen table. His class has been studying states of matter. He knows what melting is but has never formally planned an experiment.

### The feed

**AI message card**
> Here's something interesting. Ice melts faster in some conditions than others.
> Before I tell you anything else — I want you to plan an experiment to test it.
> Don't worry about doing it perfectly. Just have a go.

---

**Challenge card**
> You want to find out: **does ice melt faster in sunlight or in shade?**
>
> What would you need to do to make this a fair test?
> Type your plan in the box. Include:
> - What you'd change
> - What you'd keep the same
> - How you'd measure what happens

*[Callum types:]*
> "Put some ice in the sun and some ice in the shade. See which melts first. Use the same amount of ice."

**AI message card**
> Good start. You've got some of the right ideas.
> You said same amount of ice — that's important. Well spotted.
>
> Here's a question: what if one ice cube started at a different temperature? Would that matter?

*[Callum types: "Yes it would be different"]*

> Right. So what would you need to do about that?

*[Callum types: "Put them in the same place first maybe?"]*

> Exactly — same starting conditions. Scientists call everything you keep the same a "control variable." You identified some without knowing the word.
>
> There's one more thing missing from your plan though.
>
> Hint: how would you know WHEN the ice has melted?

*[Callum types: "Watch it? Or time it?"]*

> Both good options. Timing it is more precise — watching leaves more room for argument.
>
> Here's what a more complete version of your plan looks like:

---

**Explanation card**
> **A fair test for melting ice**
>
> **What you change (independent variable):** sunlight vs shade
>
> **What you measure (dependent variable):** time for ice to fully melt (use a stopwatch)
>
> **What you keep the same (control variables):**
> - Same size and mass of ice cubes
> - Same starting temperature (take from same freezer at same time)
> - Same container
> - Same room temperature for the "shade" condition
>
> **Why controls matter:** if you change two things at once, you can't know which one caused the difference. One change, one measure — that's a fair test.
>
> Callum — you had the key ideas. You needed the structure. That's what this was about.

---

**AI message card**
> Scientists almost never plan a perfect experiment first time.
> They plan, they find the problems, they fix the plan.
> That's exactly what happened just now.

### What happens next
The next Working Scientifically session presents a different scenario — testing which material keeps water warmest — and asks Callum to identify the control variables himself before any prompting. The AI will reference this session ("remember the ice experiment?") as an anchor.

---

## 7. What's Hiding in the Story?
**Year group:** Y3–Y4 · **Age:** 9 · **Subject:** English — Reading Inference, Hint Progression
**Scenario:** A child reads a short extract and is asked an inference question they can't immediately answer. The AI deploys the four-level hint system: metacognitive → strategic → procedural → reveal with explanation.
**Pedagogical principles:** Scaffolded hints (all four levels), productive failure, metacognitive prompts

### Setting
A weekday after school. Priya, age 9, is on a laptop. She reads confidently but finds inference questions frustrating — she often says "it doesn't say" rather than looking for implied meaning.

### The feed

**AI message card**
> Here's a short piece of text. Read it carefully.
> There's going to be a question that won't have an obvious answer — you'll need to look between the lines.

---

**Challenge card**
*[Short extract displayed:]*

> *Maya hadn't eaten since breakfast. She counted the coins in her pocket for the third time. 47p. The bakery window steamed up, warm and gold from the inside. She pressed her face against the glass for a moment, then turned and walked quickly in the opposite direction.*

> **Why does Maya walk away from the bakery?**
>
> *[Free text response field]*

*[Priya types: "It doesn't say why she walks away."]*

---

**AI message card** — *Hint Level 1: Metacognitive*
> You're right that she doesn't say why. But she does give us clues.
>
> Before you look at the words again: what kind of question is this?
> Is it asking you what happened, or asking you to explain why something happened?

*[Priya types: "Why it happened"]*

> Right — it's an inference question. That means the answer is hidden in details, not stated directly.
> Now look at the text again.

---

*[Priya resubmits: "She didn't want the bread."]*

**AI message card** — *Hint Level 2: Strategic*
> Here's a different way to think about it.
> Look at every detail the author chose to put in.
> Authors don't add details by accident. Why mention the coins? Why say she counted them three times?

*[Priya types: "She doesn't have much money?"]*

> Keep going. You're closer. What does that have to do with the bakery?

---

*[Priya types: "She can't afford to buy anything in the bakery"]*

**AI message card** — *Hint Level 3: Procedural*
> Yes — now put that together with the last thing she does.
> She walks away quickly, in the opposite direction.
> What does "quickly" tell you? What does "opposite direction" tell you?

*[Priya types: "She's embarrassed. She doesn't want people to see her looking."]*

---

**Explanation card**
> That's an inference.
>
> You found it by reading what the author chose to show:
> - She hasn't eaten since breakfast — she's hungry
> - She counts 47p three times — she knows it's not enough
> - She presses her face against the glass — she wants what's inside
> - She walks away quickly, opposite direction — she doesn't want to be seen wanting something she can't have
>
> "Embarrassed" is a great word for it. You could also say: ashamed, self-conscious, proud.
>
> The author never says any of this. But it's all there. That's inference.
>
> Priya — when you first said "it doesn't say," you were right. But you found a way in anyway. That took three different attempts. That's the work.

### What happens next
The AI notes that Priya's first instinct is to look for explicit answers. Over the next three reading sessions, it will present inference questions with increasingly subtle clues, each time asking her first: "what kind of question is this?" to build the habit of categorising before responding.

---

## 8. The Fraction That Broke Everything
**Year group:** Y5–Y6 · **Age:** 10–11 · **Subject:** Mathematics — Fractions, Productive Failure
**Scenario:** A child encounters adding fractions with different denominators before being taught a method. They attempt it using whole-number intuition and produce a misconception. The explanation arrives after the failure.
**Pedagogical principles:** Productive failure (central), effort attribution, explanation after misconception, self-comparative feedback

### Setting
A Saturday morning. Jonah, age 11, is on his laptop in his bedroom. He has been using the platform for four months. He is confident with fractions of the same denominator and has just started encountering different denominators.

### The feed

**AI message card**
> Right, Jonah. I'm going to give you something you probably haven't been taught yet.
> Have a go anyway. I'm not looking for the right answer — I'm looking for your thinking.

---

**Challenge card**
> What is 1/2 + 1/3?
>
> *[Free response field]*
> If you're not sure, show your thinking, not just your answer.

*[Jonah types: "2/5 — because 1+1=2 and 2+3=5"]*

**AI message card**
> Interesting. That logic is really common — and it makes a kind of sense.
> But here's the thing: 2/5 is actually smaller than 1/2 on its own.
> How can adding something make it smaller?

*[Jonah types: "That's weird. Oh. That can't be right."]*

> Exactly. Something's broken in the approach. What do you think went wrong?

*[Jonah types: "Maybe you can't just add the top and bottom numbers separately?"]*

> Right instinct. Here's the question: what does 1/2 actually mean? And what does 1/3 actually mean?

*[Jonah types: "1/2 means one out of two equal parts. 1/3 means one out of three."]*

> Good. Now: can you add one-out-of-two-parts to one-out-of-three-parts directly? Are the parts the same size?

*[Jonah types: "No — two equal parts are bigger pieces than three equal parts. They're different sizes. You'd have to make them the same size first?"]*

---

**Explanation card**
> You just figured out why we need a common denominator.
>
> **The rule:** you can only add fractions when the parts (denominators) are the same size.
>
> **How to make them the same size:**
>
> 1/2 and 1/3 → find a number both 2 and 3 divide into. That's 6.
>
> 1/2 = 3/6 (multiply top and bottom by 3)
> 1/3 = 2/6 (multiply top and bottom by 2)
>
> Now: 3/6 + 2/6 = 5/6
>
> You can check: 5/6 is bigger than 1/2. That makes sense.
>
> **What you spotted:** adding the numerators and denominators separately breaks the meaning of the fraction. You caught that yourself — that's the insight. The method is just the mechanics.

---

**Challenge card**
> Now try: 1/4 + 1/3

*[Jonah works through it, writing in the box:]*
> "4 and 3 both go into 12. So 1/4 = 3/12, and 1/3 = 4/12. So 3/12 + 4/12 = 7/12."

**AI message card**
> 7/12. Right.
> Three months ago you were adding fractions with the same denominator and getting some of them wrong. Now you're doing this. That's a real shift.

### What happens next
The AI schedules three more sessions on fraction addition with different denominators, then introduces subtraction of fractions before any multiplication, to establish the denominator-equivalence principle deeply before introducing new operations.

---

## 9. Back to the Map After Half Term
**Year group:** Y5–Y6 · **Age:** 10 · **Subject:** Geography — Mapwork, Returning After Gap
**Scenario:** A child returns after a two-week holiday gap. The AI names the gap, normalises forgetting, and uses a brief retrieval warm-up before introducing new content.
**Pedagogical principles:** Forgetting normalisation, self-comparative feedback, metacognitive prompts

### Setting
A Monday evening, first day of a new school term. Freya, age 10, opens the platform. She has not used it in 16 days. The app knows this because it tracks session dates.

### The feed

**AI message card**
> Freya. It's been about two weeks.
>
> Before we do anything new — fair warning: things you knew well before a break sometimes feel fuzzier after it. That's normal. Completely expected. It's how memory works.
>
> We'll start with something you've done before. Not to test you — just to warm things back up.

---

**Challenge card**
> *[Ordnance Survey map extract shown — a section of a coastal area with contour lines, symbols, and a grid.]*
>
> What do the contour lines on this map show?
>
> *[Four options:]*
> - The depth of the sea
> - The height and shape of the land
> - Roads and paths
> - Rivers and streams

*[Freya pauses, then taps: "The height and shape of the land." Correct.]*

**AI message card**
> Good. That came back.
>
> One more warm-up: what does it mean when contour lines are very close together?

*[Freya types: "Steep? Like a steep hill?"]*

> Right — close lines = steep slope. Spread out lines = gentle slope. That one's still there.

---

**Challenge card**
> *[Same map. A path is marked going up a hillside. The contour lines are very close together on the left side of the path, and more spread out on the right.]*
>
> A walker wants to reach the summit. Which side of the path would be steeper to climb — left or right?
>
> *[Interactive: tap left or right on the map.]*

*[Freya taps left.]*

**AI message card**
> Left — correct. You read the contour lines straight off.
>
> Now. New bit. We haven't done this before the holiday.

---

**Challenge card**
> *[Same map, with a grid reference question.]*
>
> What is the four-figure grid reference for the church symbol marked on this map?
>
> *[The map has a grid overlaid, numbers 1–8 across the bottom and 1–8 up the side. A cross symbol (church) sits at approximately grid square 35, 72.]*
>
> *[Interactive: slide two cursor bars to select the easting and northing.]*

*[Freya looks uncertain. She moves the sliders. Puts in 37, 72.]*

**AI message card**
> Nearly. You've got the northing exactly right — 72.
> The easting is slightly off. Remember: you read the grid "along the corridor, then up the stairs."
> Try again — go along the bottom first.

*[Freya adjusts: 35, 72.]*

> 35 72. That's it.
> First go at grid references after a break and a new concept — solid.

---

**Explanation card**
> **Four-figure grid references**
>
> A grid reference tells you which square on the map you mean.
>
> **Easting first** — the numbers along the bottom (left to right). Go to the LEFT edge of your square.
>
> **Northing second** — the numbers up the side (bottom to top). Go to the BOTTOM edge of your square.
>
> Memory trick: **"Along the corridor, then up the stairs."**
>
> Four-figure references locate a whole grid square (100m × 100m on a 1:25,000 OS map). Six-figure references pinpoint a spot within the square — you'll do those next time.

### What happens next
The next session begins with a four-figure grid reference retrieval question (no introduction, just a test of what stuck), then introduces six-figure references as the next step.

---

## 10. You Choose — But Only a Little
**Year group:** Y5–Y6 · **Age:** 10–11 · **Subject:** Computing — Decomposition, Micro-Autonomy
**Scenario:** A child is working through a problem-decomposition task and reaches a fork where the AI offers a genuine small choice — two routes to the same learning goal. The child picks one. The AI adapts.
**Pedagogical principles:** Micro-autonomy, metacognitive prompts, effort attribution

### Setting
An evening session. Amir, age 11, has been using the platform for six weeks. He is interested in games and has mentioned Minecraft twice in previous typed responses (the AI noted this). He is working on decomposition — breaking big problems into smaller parts.

### The feed

**AI message card**
> Right, Amir. Decomposition — breaking a big problem into pieces.
>
> Here's a scenario: you're going to design a school timetable-making program. Not build it. Just figure out what it would need to do.
>
> You've got a choice of how to think about it:
> - Option A: Think about it like a user — what would a teacher need to do with it?
> - Option B: Think about it like a programmer — what steps would the computer need to follow?
>
> Either works. Which feels more natural?

*[Amir taps: Option B — programmer.]*

---

**AI message card**
> Programmer lens it is.
>
> Break the problem down. What would the computer need to do FIRST, before anything else?
>
> Don't try to list everything — just the first step.

*[Amir types: "It needs to know which teachers there are and what subjects they teach"]*

> Good. That's collecting the input. Keep going — what's the next thing?

*[Amir types: "Know what rooms are available and how many students fit"]*

> Nice. You're decomposing without being told to. What are you actually doing right now?

*[Amir types: "Making a list of all the information it needs?"]*

> Exactly — you're separating the problem into: what it needs to know, and what it needs to do. Those are different. Keep that distinction in mind.

---

**Challenge card**
> You've identified the inputs. Now — what would the program need to CHECK for each possible timetable it creates?
>
> List at least three things it would have to verify.

*[Amir types:]*
> "1. No teacher is in two places at once
> 2. No room has two classes at the same time
> 3. All subjects are covered for each class"

**AI message card**
> Three valid constraints. These are exactly the conditions a real scheduling algorithm checks.
>
> Here's the terminology: these are called **constraints**. Your decomposition has identified the inputs and the constraints. What's the third category — the thing the program is actually supposed to produce?

*[Amir types: "The finished timetable?"]*

> Yes — the output. Inputs, constraints, output. You just decomposed a real scheduling problem.
>
> School timetabling is genuinely hard — it's an NP-hard computational problem. Schools actually use software that brute-forces thousands of combinations and checks each one against constraints.
>
> You just described how it works.

---

**AI message card**
> Last thing — if the Option A route (user perspective) had come up first, you'd have ended up in the same place, just from a different angle.
> That's what decomposition is: multiple ways to break the same problem apart.

### What happens next
The AI introduces an actual mini-problem for Amir to decompose — planning a school trip — and asks him to use the same three-category framework (inputs, constraints, output) independently before any prompting.

---

## 11. What Is the Author Doing Here?
**Year group:** Y5–Y6 · **Age:** 11 · **Subject:** English — Reading for Authorial Intent, Metacognitive Prompts
**Scenario:** A child reads a persuasive text extract and is guided through metacognitive questioning before diving into the authorial intent analysis.
**Pedagogical principles:** Metacognitive prompts, scaffolded hints, effort attribution

### Setting
An after-school session. Grace, age 11, is on a laptop. She reads well and tends to focus on literal comprehension. Her responses in previous sessions show she understands what texts say but rarely asks why the author wrote things in a particular way.

### The feed

**AI message card**
> Grace. Before you read this next thing, I want to ask you something.
>
> When you read — what are you usually thinking about?
>
> *[Multiple choice:]*
> - What's happening in the story / text
> - What words mean
> - Why the author made those choices
> - All of those roughly equally

*[Grace taps: "What's happening in the story / text"]*

> Right. Most readers start there. That's correct and necessary.
> But "reading for authorial intent" means adding a layer: not just "what does this say" but "why did they say it like THIS?"
> Keep that question in your head while you read.

---

**Challenge card**
*[Persuasive text extract displayed:]*

> *Britain's forests are disappearing. Every year, thousands of hectares of ancient woodland — irreplaceable, millennia-old — are cleared for development. We are not losing trees. We are losing time.*

> **What is the author trying to do in this paragraph?**
>
> *[Free response field.]*

*[Grace types: "Persuade people that forests are being cut down."]*

**AI message card**
> That's the topic and general purpose. Now go deeper.
>
> Look at the specific words they chose. Why "irreplaceable"? Why "millennia-old"? Why end with "We are not losing trees. We are losing time."?
>
> What effect do those choices have on you as a reader?

*[Grace types: "It makes it sound more serious. Like it's not just trees it's really old important things."]*

> Good. The word "irreplaceable" means it can't be got back. The phrase "millennia-old" uses a huge unit of time to make the reader feel the age and value.
>
> Now — why do you think the author wrote "We are not losing trees. We are losing time." as two short sentences rather than one long one?

*[Grace types: "For impact? Short sentences feel more serious."]*

**AI message card**
> Exactly. Short sentences punch harder. They land like statements of fact. If it read "We are not merely losing trees but losing time" — same words, different rhythm — it would feel softer, less certain.
>
> The author chose certainty, not argument. They're telling you, not persuading you — even though this is persuasive writing.
>
> That gap between what the text does and how it achieves it — that's authorial intent.

---

**Explanation card**
> **Reading for authorial intent — the key questions:**
>
> 1. What is the writer trying to make me feel or think?
> 2. What specific choices (words, sentence length, structure) do they use to create that effect?
> 3. Why those choices rather than other possible choices?
>
> When you answer a question about authorial intent, you're answering all three at once:
> *"The writer uses [technique] to create [effect] because [reason for that choice]."*
>
> Grace — you started by saying "persuade people that forests are cut down." By the end you'd spotted sentence length, word choice, and emotional register. That's a big move in one session.

### What happens next
The AI presents a contrasting extract — a factual report on the same topic — and asks Grace to identify where the authorial intent differs, and how the choices change as a result.

---

## 12. When Everything Clicks
**Year group:** Y5–Y6 · **Age:** 11 · **Subject:** Mathematics — On-a-Roll Scenario
**Scenario:** A child is in flow — answering correctly, quickly, and with growing confidence. The AI recognises this not with praise but by subtly increasing difficulty, and by reflecting the child's own strategies back at them.
**Pedagogical principles:** Self-comparative feedback, effort attribution, interleaving, metacognitive prompts

### Setting
A weekday after school. Lily, age 11, is on a tablet. She is a confident mathematician who can get bored if challenge is too low. Today she is sharp — response times are fast, no backtracking. The AI detects an on-a-roll pattern from response quality and pace.

### The feed

**Challenge card**
> 3/4 × 2/3 = ?

*[Lily types: 6/12 = 1/2. Correct and simplified.]*

**Challenge card**
> 5/6 ÷ 1/3 = ?

*[Lily types: 5/2 = 2 and a half. Correct.]*

**Challenge card**
> A recipe needs 2/3 of a cup of sugar. Lily is making 1.5 × the recipe. How much sugar does she need?

*[Lily types: "2/3 × 3/2 = 6/6 = 1 cup." Correct.]*

**AI message card**
> You converted 1.5 to 3/2 without being asked to. Where did that come from?

*[Lily types: "It's easier to multiply fractions than decimals"]*

> Right — and that's a genuine mathematical preference, not a rule. You chose the cleaner method.
>
> I'm going to make the next one harder.

---

**Challenge card**
> A water tank is 3/5 full. It holds 120 litres when completely full.
> Water is draining at 2/5 of the tank per hour.
> How long until the tank is empty?

*[Lily works in the response box:]*
> "3/5 of 120 = 72 litres in the tank.
> 2/5 of 120 = 48 litres drained per hour.
> 72 ÷ 48 = 1.5 hours"

**AI message card**
> 1.5 hours. Correct.
>
> What you did there: turned a fraction-of-a-fraction problem into a rate problem. That's a step up from what you've been doing. You didn't hesitate.

---

**Challenge card**
> A rectangle has area 7/8 m². Its width is 7/12 m. What is its length?

*[Lily types: "7/8 ÷ 7/12 = 7/8 × 12/7 = 12/8 = 3/2 = 1.5m"]*

**AI message card**
> 1.5m. Right.
>
> Six months ago you were asking the app to check whether 1/2 + 1/3 made sense. Today you did that.
> Same person. More tools.

### What happens next
The AI introduces percentage-fraction equivalence in the next session, using the strategy-awareness Lily showed today ("it's easier to multiply fractions than decimals") as a bridge: "You said fractions are sometimes cleaner than decimals. Let's look at when that's true."

---

## 13. The Equation That Didn't Make Sense
**Year group:** Y7 · **Age:** 11–12 · **Subject:** Mathematics — Algebra Introduction, Productive Failure
**Scenario:** A Year 7 student encounters an equation for the first time and attempts to solve it using arithmetic intuition. The misconception (treating the variable as a label rather than an unknown) is exposed and addressed.
**Pedagogical principles:** Productive failure, scaffolded hints, effort attribution, collegial voice

### Setting
A Monday evening. Daniel, age 12, is on a laptop. He is in his first term of secondary school. He has strong arithmetic and has used the platform since Year 5. He has never formally done algebra.

### The feed

**AI message card**
> Algebra. New thing. No prior knowledge needed — just your thinking.
>
> Here's a statement:
>
> 3x + 5 = 14
>
> What do you think x is? Have a go. Show your reasoning.

*[Daniel types: "x is probably a number. 3 times something plus 5 = 14. So 3 times something = 9. So x = 3."]*

**AI message card**
> 3. That's correct. And your reasoning was exactly right.
>
> Here's the interesting part — you just solved an equation without being taught a method. You used logic. That logic has a name: inverse operations.
>
> Let me try a different one.

---

**Challenge card**
> 5x − 3 = 2x + 9
>
> Find x.

*[Daniel types: "x = something... 5 times something minus 3 = 2 times something plus 9. I'm not sure how to do both sides at once."]*

**AI message card**
> Good — you've spotted the actual problem. Both sides have x in them. That makes it different.
>
> Here's a question: if x is the same value on both sides (which it is), what could you do to make x appear on only one side?

*[Daniel types: "Subtract x from both sides? But then it's 4x, not 5x."]*

> Right — if you subtract 2x from both sides, the right side has no x. The left side has 3x. That's progress. Keep going.

*[Daniel types: "3x − 3 = 9. Then 3x = 12. Then x = 4."]*

**AI message card**
> 4. Correct.
>
> Check it: 5(4) − 3 = 17. 2(4) + 9 = 17. They match.
>
> What you just did — rearranging until x is isolated — is the central idea in solving linear equations. Everything else is just more complex versions of that move.

---

**Explanation card**
> **Solving equations with x on both sides**
>
> The goal: get all the x terms on one side, all the numbers on the other.
>
> **Method:**
> 1. Subtract the smaller x term from both sides (to remove x from one side)
> 2. Add or subtract numbers to isolate x
> 3. Divide to find x
>
> **Why it works:** an equation is a balance. Whatever you do to one side, you do to the other. Balance is maintained.
>
> The logic you used on the first problem (inverse operations — undoing what's been done to x) is exactly the same logic. You scaled it up.

---

**Challenge card**
> 4x + 7 = 2x + 15
>
> Find x. Show your steps.

*[Daniel works through it correctly: 2x = 8, x = 4.]*

**AI message card**
> Right. And you didn't need the method explained again.
> You generalised it yourself.

### What happens next
The AI introduces equations with x on one side but requiring two steps (e.g., 3x + 4 = 22 → confirmation of mastery) before progressing to negative x terms in the next session. It schedules a return to the x-on-both-sides type in four sessions' time to test retention.

---

## 14. Before You Know How to Test It
**Year group:** Y7 · **Age:** 12 · **Subject:** Science — Planning Enquiry, Hypothesis Before Instruction
**Scenario:** A student is asked to form a hypothesis and plan an investigation before any methodology has been taught. The AI is looking for scientific reasoning, not procedural accuracy.
**Pedagogical principles:** Productive failure, metacognitive prompts, effort attribution, collegial voice

### Setting
An evening session. Niamh, age 12, is on a laptop. She is curious about science and tends to write detailed responses. The topic is forces — specifically, the relationship between mass and gravitational potential energy.

### The feed

**AI message card**
> Here's a scenario. No instruction first — I want your thinking before we discuss the method.
>
> You drop two balls from the same height. One ball has mass 100g. The other has mass 500g. They're the same size and shape.
>
> Write a prediction: what do you think will happen, and why?

*[Niamh types:]*
> "They'll both hit the ground at the same time, because gravity pulls everything at the same rate regardless of mass. But the heavier one will have more energy when it lands because it has more mass."

**AI message card**
> Interesting — both parts of that are worth unpacking.
>
> "Gravity pulls everything at the same rate regardless of mass" — where did that idea come from?

*[Niamh types: "I think I read it somewhere. Or maybe a teacher said it. Galileo?"]*

> Galileo, yes — the famous thought experiment about dropping balls from the Tower of Pisa. That intuition is correct in a vacuum. In air, there are complications — but for objects of the same size and shape, it holds well.
>
> Your second claim — the heavier one has more energy — that's also correct. Can you say more about why?

*[Niamh types: "More mass means more... weight? And more weight falling means more energy? I'm not totally sure of the equation."]*

> You've got the right shape of reasoning — mass is part of the energy calculation. You don't need the equation yet. The idea that energy depends on mass is sound.
>
> Now: if you wanted to test the two-balls prediction experimentally — what would you actually do?

---

**Challenge card**
> Design a simple experiment to test whether two objects of different mass but same size hit the ground at the same time when dropped from the same height.
>
> What would you change, what would you keep constant, how would you measure the result?

*[Niamh writes a detailed plan including: same height, same object shape, timing with a stopwatch, multiple trials, and she adds: "But a stopwatch isn't accurate enough — we'd need something slower or a camera."]*

**AI message card**
> The camera point is exactly what physicists do. High-speed cameras are used in real experiments to measure short time intervals precisely. You identified a genuine limitation of the method.
>
> This is good enquiry planning. You're not just listing steps — you're critiquing your own method before you run it. That's the actual skill.

---

**Explanation card**
> **Gravitational potential energy:**
>
> GPE = mass × gravitational field strength × height
>
> GPE = m × g × h
>
> On Earth, g = 9.8 N/kg (or approximately 10 N/kg for calculations).
>
> So yes: a 500g object at 1m height has 5× the GPE of a 100g object at the same height. Your prediction was right.
>
> **Why they fall at the same rate despite different masses:**
> Greater mass means more gravitational force pulling down — but also more inertia (resistance to acceleration). These effects cancel exactly. That's why Galileo's insight holds.
>
> Niamh — you had both of those ideas before seeing the equation. The equation is just the formalism for what you already understood.

### What happens next
The AI presents a GPE calculation problem in the next session and references Niamh's camera observation: "You said a stopwatch wouldn't be precise enough. Here's a case where we need exact numbers — let's use the equation."

---

## 15. What Can This Source Actually Tell Us?
**Year group:** Y8 · **Age:** 13 · **Subject:** History — Source Analysis, Sophisticated Voice
**Scenario:** A Year 8 student is working with a primary source — a Victorian newspaper extract. The AI engages with the content itself rather than the student's performance, treating the source as genuinely interesting.
**Pedagogical principles:** Collegial voice, metacognitive prompts, effort attribution, self-comparative feedback

### Setting
A weekday evening. Theo, age 13, is on a laptop. He enjoys history and writes with a dry, slightly ironic style himself — the AI has picked up on this across previous sessions. He is studying the Industrial Revolution.

### The feed

**AI message card**
> Source work. There's a Victorian newspaper extract below from 1843.
> Read it carefully before you do anything else. This one is interesting.

*[Source displayed:]*

> *"The working classes, when not under the direct supervision of their employers, are prone to idleness, vice, and an abandonment of those moral values which distinguish the civilised man from the savage. It is therefore the duty of the mill-owner not merely to provide employment, but to instruct his workers in punctuality, sobriety, and godliness."*
> — From a Manchester newspaper editorial, 1843

> **Question 1:** What is this source trying to argue?

*[Theo types:]*
> "That mill owners have a responsibility to control the moral lives of their workers, because workers are essentially assumed to be irresponsible without oversight."

**AI message card**
> That's a precise reading. Note the phrase "prone to idleness, vice" — what assumptions does the writer embed in that language?

*[Theo types:]*
> "That being poor or working-class means you're inherently less moral or disciplined. It's circular — they assume the conclusion and then build the argument on top of it."

> Right — that's called a circular argument. The writer presupposes the inferiority of working-class people, then uses that presupposition to justify paternalistic control. The argument only works if you accept the premise, which the writer never proves.
>
> Now the harder question.

---

**Challenge card**
> **Question 2:** What can this source tell us, and what can it NOT tell us, about the lived experience of mill workers in 1843?

*[Theo types:]*
> "It can tell us what the ruling class believed, or at least publicly claimed to believe, about workers. It tells us something about the ideological justification for the conditions of industrial labour. It can't tell us what workers actually thought or experienced — it's not their voice at all."

**AI message card**
> That's the distinction. The source is evidence of ideology, not of lived experience.
>
> One more layer: why was this argument appearing in a newspaper in 1843 specifically? What was happening that year that might have made mill owners anxious about the idea of workers having unsupervised time?

*[Theo types:]*
> "The Chartist movement was active. There were strikes. The idea of workers organising or thinking politically would have been threatening to people like this writer."

> That's contextual sourcing. You've used external knowledge to ask why the source exists, not just what it says. That's the most sophisticated thing you can do with a primary source.
>
> In an exam, that's the difference between a response that describes the source and one that uses it.

---

**AI message card**
> Last year you were summarising sources — restating what they say.
> Today you unpacked the circular logic, identified the ideological function, and placed the source in political context. That's a different kind of reading.

### What happens next
The AI presents a contrasting source in the next session — a letter written by a mill worker in the same period — and asks Theo to compare what each source can and cannot tell us about the same period.

### Parent notification
**Triggered because:** A significant leap in analytical sophistication occurred, and it connects to a real-world conversation topic.

> **From the learning app — Theo's history session**
>
> Theo worked with a Victorian newspaper editorial today — the kind of text that argued mill owners needed to "control the moral values" of their workers. He spotted that the argument was circular (assuming working-class inferiority rather than proving it) and that the source couldn't tell us what workers actually thought — only what the ruling class wanted people to believe.
>
> He also connected it to the Chartist movement unprompted, which was a major political context.
>
> This kind of source analysis — asking not just "what does this say?" but "why does this exist, and whose interests does it serve?" — is useful beyond history. You could ask the same question about a lot of things you read in the news.

---

## 16. Between the Lines, Again — But Better
**Year group:** Y8 · **Age:** 13 · **Subject:** English — Inference from Novel Extract, Self-Comparative Feedback
**Scenario:** A student reads an extract from a novel and answers an inference question. The AI uses self-comparative feedback to show growth — contrasting the quality of today's response with a response from six weeks ago.
**Pedagogical principles:** Self-comparative feedback, effort attribution, collegial voice, metacognitive prompts

### Setting
A Sunday afternoon. Zara, age 13, is on her laptop. She has been using the platform for two months. Six weeks ago she answered a similar inference question and the AI noted the response quality. Today, presenting similar material, it will reference that earlier moment.

### The feed

**AI message card**
> There's an extract below from a novel. One question after it.
> This is inference — you've done this before.

*[Extract displayed:]*

> *He sat at the end of the table, as he always did. His food was untouched. He nodded at things people said, but his eyes tracked the clock above the door, as though each minute was something to get through. When the meal was finished and his wife began to clear the plates, he stood abruptly — "I'll do that" — in a tone that allowed no argument.*

> **What do we understand about this man's state of mind, and how does the author create that impression?**

*[Zara types:]*
> "He seems distracted and uncomfortable. He's not eating, not really listening, and keeps watching the clock like he wants to leave. When he offers to clear up it feels controlling rather than helpful — 'in a tone that allowed no argument' tells us he shut down any possibility of disagreement. The author shows this through his actions and body language rather than telling us directly. The detail about the clock is effective — 'each minute was something to get through' implies endurance rather than enjoyment."

**AI message card**
> That's a clear, well-structured inference response.
>
> You picked up the clock detail and gave an interpretation ("endurance rather than enjoyment") — that's the analytical move that matters. You also distinguished between what he says and what it means in context — "I'll do that" as control rather than kindness.
>
> Six weeks ago I gave you a similar task — a character sitting apart at a gathering — and you wrote: "He seems unhappy and doesn't want to be there."
>
> That was accurate. Today's response does something different. What's the difference?

*[Zara types:]*
> "Before I just said what I thought he felt. Today I explained how I know — what in the text actually makes me think that."

> That's it exactly. The inference is the same. The analytical move — pointing to evidence and explaining its effect — is what changed.
>
> In an exam, that move is what separates description from analysis.

---

**Challenge card**
> One more question on the same extract.
>
> The author writes: "his eyes tracked the clock above the door, as though each minute was something to get through."
>
> Why does the author use "tracked" rather than a simpler word like "watched" or "looked at"?

*[Zara types:]*
> "'Tracked' implies deliberate, focused attention — like surveillance or following prey. It makes it feel obsessive or anxious rather than just casual glancing. 'Watched' would be more neutral. 'Tracked' gives the action an uncomfortable intensity."

**AI message card**
> "Like surveillance or following prey" — that's an interesting connotation you've pulled in. The word does carry that sense of focus that won't let go.
>
> That level of attention to word choice — asking why this word and not another word — is what close reading actually is.

### What happens next
The AI will return to word-choice analysis in the next session, using a different genre (a poem), and explicitly tells Zara: "Same skill, different form. See if the move transfers."

---

## 17. The Pattern Nobody Can Find
**Year group:** Y9 · **Age:** 14 · **Subject:** Geography — Human Geography, Struggling Scenario + Hint Progression
**Scenario:** A student is struggling with a question about global economic inequality and the relationship between GDP and development. They are frustrated and giving vague answers. The AI responds without condescension and deploys the hint progression.
**Pedagogical principles:** Scaffolded hints (all levels), effort attribution, forgetting normalisation, collegial voice

### Setting
A weekday evening. Kwame, age 14, is on a laptop. He has found the current topic (global development and inequality) abstract and frustrating. His last three sessions have produced shorter and shorter responses. The AI has flagged a disengagement pattern and is adjusting.

### The feed

**AI message card**
> Kwame — development. You've found this topic hard to get hold of, which makes sense. The concepts are genuinely abstract.
>
> I'll be direct: if any question is unclear, say so and I'll reframe it. No need to guess at what I'm asking.

---

**Challenge card**
> Chad has a GDP per capita of approximately $700. Norway has a GDP per capita of approximately $90,000.
>
> What does this difference tell us about the lives of people in these two countries? What doesn't it tell us?

*[Kwame types: "Norway is richer. People there have more money."]*

**AI message card** — *Hint Level 1: Metacognitive*
> That's correct as far as it goes. Here's a reframe: what kind of question is this asking?
>
> Is it asking you to describe the difference in numbers, or to explain what that difference means for people's actual lives?

*[Kwame types: "What it means for their lives I think."]*

> Right. So: what might it mean to live in a country where the average income is $700 a year, compared to $90,000?

*[Kwame types: "You'd have less money for stuff. Less healthcare and things."]*

**AI message card** — *Hint Level 2: Strategic*
> Good — healthcare is a real one. Think about categories of basic need.
>
> What do people need beyond money directly: things like education, healthcare, life expectancy, access to clean water?
> Which of those might be affected by a country's wealth?

*[Kwame types: "All of them probably. If a country is poor the government has less money to spend on hospitals and schools."]*

> Exactly — GDP per capita partly predicts what governments can invest in public services.
>
> Now for the second part of the question: what does GDP per capita NOT tell us?

*[Kwame types: "I'm not sure what you mean."]*

**AI message card** — *Hint Level 3: Procedural*
> Think about it this way: GDP per capita is an average — total GDP divided by population.
>
> If a country has a few extremely wealthy people and many extremely poor people, what does the average hide?

*[Kwame types: "It would look higher than it is for most people? Because the rich people push the average up."]*

> That's it. So a high GDP per capita doesn't tell you how equally wealth is distributed. A country could have a high average and still have widespread poverty.
>
> What other things does GDP not measure?

*[Kwame types: "Happiness? Whether people like living there. Environmental damage."]*

**AI message card**
> All of those are real limitations. Economists actually measure things like the Human Development Index (HDI), which combines GDP per capita with life expectancy and education — because GDP alone misses too much.
>
> You got there by being pushed. That's fine. The question was genuinely abstract. Your thinking was right once it started moving.

---

**Explanation card**
> **GDP per capita: what it shows and what it misses**
>
> **Shows:**
> - Average economic output per person
> - Broad indicator of a country's wealth
> - Correlates with public service capacity (healthcare, education, infrastructure)
>
> **Misses:**
> - Income inequality (Gini coefficient measures this separately)
> - Environmental costs of economic activity
> - Wellbeing, happiness, social cohesion
> - Informal economy activity
> - Quality of life beyond material wealth
>
> **Alternative measures:** Human Development Index (HDI), Multidimensional Poverty Index, Genuine Progress Indicator
>
> Kwame — this took a while because the question was genuinely asking two things at once. Your instinct to go to healthcare first was right.

### What happens next
The AI schedules a return to GDP vs HDI in the following session with a concrete country comparison task. It will not mention the difficulty of this session unless Kwame does — there is no shame attached to needing hints.

---

## 18. What Is Abstraction, Actually?
**Year group:** Y9 · **Age:** 14–15 · **Subject:** Computing — Abstraction, Collegial Dry Voice
**Scenario:** A Year 9 student explores the concept of abstraction in computing. The AI treats the concept as genuinely interesting rather than instrumentally teaching it, and engages with the ideas directly.
**Pedagogical principles:** Collegial voice, metacognitive prompts, micro-autonomy, effort attribution

### Setting
A Sunday afternoon. Asha, age 15, is on a laptop. She is confident, a little impatient, and tends to find computing theory dry. She has written in previous sessions that she prefers the practical side. The AI has noted this and is going to approach abstraction through a real example first.

### The feed

**AI message card**
> Abstraction. This one is actually interesting — though it's taught in a way that makes it sound boring.
>
> Here's a question before anything else: when you drive (or imagine driving) a car, how much do you know about how the engine works?

*[Asha types: "Basically nothing. You just use the pedals and wheel."]*

> Right. You interact with the car through a very simplified interface — pedals, wheel, gearstick. The internal combustion process is completely hidden. You don't need to know it to drive.
>
> That hiding of complexity behind a simpler interface — that's abstraction.
>
> Computing does this constantly. The question is: why, and at what cost?

---

**Challenge card**
> When you write a Python function — let's say `print("hello")` — you have no idea what the computer is actually doing at the hardware level to make those letters appear on screen.
>
> List as many layers between your Python line and the physical screen as you can think of.

*[Asha types:]*
> "Python interpreter, probably some kind of OS layer, graphics card, the screen itself. Maybe some memory stuff in the middle."

**AI message card**
> That's roughly right — and the actual stack is more complex. Python → bytecode → virtual machine → OS system call → graphics driver → GPU → display hardware.
>
> Each layer only communicates with the layer directly above and below it. Each layer abstracts everything below it.
>
> Here's the interesting design question: why not expose all of that to the programmer?

*[Asha types: "Because nobody would ever get anything done. You'd spend all your time dealing with hardware."]*

> Exactly — abstraction enables productivity. But there's a cost. What might it be?

*[Asha types: "You lose control? If something goes wrong deep down you might not be able to fix it."]*

> That's the real tension. Abstraction gives power through simplification, but it also introduces opacity — you can't see what's happening below. In security, that's a genuine problem. A bug at a layer you can't access is a bug you can't fix.
>
> The people who wrote the Python interpreter made choices — what to expose, what to hide. Every interface you've ever used was a set of those decisions.

---

**Challenge card**
> In object-oriented programming, you create a class — say, a `BankAccount` class. The balance is stored as a private variable. External code can call `deposit()` and `withdraw()` but can't directly change the balance number.
>
> How is this an example of abstraction? What does it hide, and why is that useful?

*[Asha types:]*
> "It hides the actual implementation — how the balance is stored and updated — behind a clean interface. If you change how the balance is stored internally later, the external code doesn't need to change. It also stops accidental or malicious direct modification of the balance."

**AI message card**
> Both reasons are real: maintainability and security. The bank account example also shows that abstraction is a design decision about trust — who is allowed to know what, and who is allowed to do what.
>
> That's more interesting than "hiding unnecessary detail," which is how it's usually defined.

---

**Explanation card**
> **Abstraction in computing — a more honest definition:**
>
> Abstraction is the practice of representing a complex system through a simplified interface that exposes only what users of that system need to interact with.
>
> It is not just "hiding complexity" — it is a design decision about what to reveal and what to conceal, and why.
>
> **Examples:**
> - A function signature (you know the inputs and outputs; the implementation is hidden)
> - A class with private attributes (the interface is controlled)
> - An API (you access a service through defined endpoints; the server internals are opaque)
> - A high-level programming language (you write logical instructions; hardware implementation is concealed)
>
> **The trade-off:** abstraction enables productivity and reduces cognitive load. It also creates opacity, which can make debugging harder and can obscure performance costs.
>
> Asha — you said at the start that you find theory dry. You spent 15 minutes on abstraction. Make of that what you will.

### What happens next
The AI presents a practical task in the next session: refactor a messy function by introducing appropriate abstraction, then explain what they chose to hide and why. The conceptual work done today becomes the framework for a hands-on task.

---

## 19. Summer Is Over — Hello Again
**Year group:** Y6 · **Age:** 10 · **Subject:** Mathematics (cross-cutting — forgetting normalisation)
**Scenario:** A child returns after the summer holidays. The platform detects an 8-week gap. The AI does not pretend nothing happened. It names the gap, sets expectations about struggle, and begins with retrieval before any new content.
**Pedagogical principles:** Forgetting normalisation, self-comparative feedback, scaffolded hints, effort attribution

### Setting
Early September. Elliot, age 10, opens the platform for the first time since July. The last session was 58 days ago. It is a Sunday evening before the first week back at school.

### The feed

**AI message card**
> Elliot. 58 days. That's the whole summer.
>
> Here's what you should know before we start: a lot of what you knew in July will feel fuzzier now. That's not you forgetting — that's memory working normally. It needs a reason to hold onto things.
>
> We're going to spend the first few minutes on things you already knew, to wake them back up. Some will come straight back. Some will take a minute. Either is fine.

---

**Challenge card**
> In July you were working on long division.
>
> 312 ÷ 4 = ?
>
> *[Take your time. Show your working if that helps.]*

*[Elliot types: 78. Correct.]*

**AI message card**
> Still there.

---

**Challenge card**
> 756 ÷ 6 = ?

*[Elliot takes longer. Types 120. Incorrect.]*

**AI message card**
> Not quite. 6 × 120 = 720. That's 36 short of 756.
>
> Try again from where you went wrong. What's 756 − 720?

*[Elliot types: 36. Then: 36 ÷ 6 = 6. Then: 120 + 6 = 126.]*

**AI message card**
> 126. Right. You got there — you just had to rebuild the last step.
>
> That kind of error (getting most of it right, losing track at the end) is very typical after a break. It's not the concept going missing — it's the procedure getting rusty. That's different, and it comes back faster.

---

**Challenge card**
> 896 ÷ 7 = ?

*[Elliot works through it more carefully this time. Types 128. Correct.]*

**AI message card**
> Right. Quicker than the last one.
>
> That's not a coincidence — the process of making an error and correcting it actually helps more than just getting it right first time.

---

**AI message card**
> Here's what we're doing this term: fractions, decimals, percentages — linking them together. And eventually geometry.
>
> Last year (before the summer) you were getting 4-digit division mostly right but sometimes losing track mid-calculation. Today you made one error and fixed it yourself. We'll pick up from there.
>
> Not starting from scratch. Not pretending summer didn't happen. Just picking it back up.

### What happens next
The AI schedules one more retrieval session before introducing any new content — multiplication with larger numbers and some fraction recall. Only after two retrieval sessions does it introduce the new term's material.

### Parent notification
**Triggered because:** First session back after summer. Parents need to know what's happening and set expectations at home.

> **From the learning app — Elliot's first session back after summer**
>
> Elliot just completed his first session after the summer break — 58 days since his last one.
>
> We started with long division, which he was working on in July. He got the first problem straight away, made one error on the second, and fixed it himself before getting the third right. That's a normal post-summer pattern — the concept is still there, the procedure needs a little warming up.
>
> This week on the app we'll be doing retrieval before anything new. If he's doing maths in school too, that reinforcement will help.
>
> One thing worth saying: if he complains that things feel harder or that he's "forgotten everything" — that's expected and temporary. Worth validating that rather than reassuring him it'll be fine.

---

## 20. Going Back to Understand Going Forward
**Year group:** Y4 · **Age:** 9 · **Subject:** Mathematics — Struggling Child, Stepping Back to Prerequisites
**Scenario:** A child who has been given multiplication questions is consistently making errors that reveal a gap in understanding addition regrouping. The AI steps back to the prerequisite — not as a punishment but as a natural necessity.
**Pedagogical principles:** Scaffolded hints, forgetting normalisation, effort attribution, self-comparative feedback

### Setting
A weekday afternoon. Maya, age 9, has been attempting 2-digit × 1-digit multiplication using the standard written method. She has made the same carrying error four times in three sessions. The AI detects the pattern and pivots.

### The feed

**AI message card**
> Maya — I've noticed something across the last few sessions.
>
> When you multiply and get to the carrying step, something's going slightly wrong.
>
> I want to go back a bit — not because you've failed at the multiplication, but because there's something underneath that might be worth shoring up. It'll make the multiplication easier.

---

**Challenge card**
> 47 + 36 = ?
>
> Show your working in the box.

*[Maya types: "47 + 36 = 73. 7+6=13, write 3 carry 1. 4+3=7. 73."]*

**AI message card**
> Right. You did that correctly and explained every step.
>
> Let's go a bit harder.

---

**Challenge card**
> 68 + 47 = ?

*[Maya types: "68 + 47 = 105. 8+7=15, write 5 carry 1. 6+4=10, +1=11. 115." — Error: she wrote 115 instead of 115.]*

*Wait — this is actually correct: 68 + 47 = 115. The AI detects she wrote the answer right.*

**AI message card**
> That one's right. You got the double-carry (tens and hundreds) — that's the tricky part.
>
> Here's the connection to multiplication.

---

**Challenge card**
> 34 × 6 = ?
> Use the written method. Show every step.

*[Maya writes:]*
> "34 × 6.
> 4 × 6 = 24. Write 4, carry 2.
> 3 × 6 = 18. 18 + 2 = 20.
> Answer: 204"

**AI message card**
> 204. Right.
>
> Do you see the carry step? It's the same thing you did in the addition — carrying the tens into the next column. In multiplication, you're doing addition inside the multiplication process.
>
> That's why the addition step matters. It's not a different skill.

---

**Challenge card**
> 57 × 8 = ?

*[Maya carefully works through it:]*
> "7 × 8 = 56. Write 6, carry 5. 5 × 8 = 40. 40 + 5 = 45. Answer: 456"

**AI message card**
> 456. That's it.
>
> Two sessions ago you were making carrying errors at exactly that step — 5 × 8 = 40, then adding the carry. Today you got it. The carry from the units is what was slipping.
>
> It wasn't the multiplication. It was that one step inside it. Now you know what it was.

### What happens next
The AI returns to 2-digit × 1-digit multiplication across the next two sessions before moving to 2-digit × 2-digit. It will not return to addition prerequisite work unless new errors suggest a different gap.

---

## 21. What Your Parent Received Tonight
**Year group:** Y5 · **Age:** 10 · **Subject:** English — Parent Notification, Effort-Focused
**Scenario:** A child has had a session involving genuine productive struggle — not a breakthrough, not a failure, but sustained effort across a difficult inference task. The parent notification fires because of effort quality, not outcome.
**Pedagogical principles:** Parent notifications (effort-focused, not score-focused, content-rich, prompt conversation)

### Setting
A Tuesday evening. Oliver, age 10, has spent 22 minutes working through a difficult reading session. He has not reached a definitive "breakthrough" moment — but he has attempted the same inference question four times with different approaches, and each attempt has been more sophisticated than the last. No correct answer arrived. The AI has responded with genuine engagement throughout.

### The Session (abbreviated)

*[Oliver encountered an extract from a novel about a boy hiding a secret from his family. The question: "Why does the author describe the house as being 'loud with silence'?"]*

*[Four attempts, each more analytical:]*
- Attempt 1: "It means it's quiet."
- Attempt 2: "It's an oxymoron. It describes a silence that feels loud."
- Attempt 3: "The silence feels like something is being avoided — the house should have noise but doesn't."
- Attempt 4: "The 'loud' silence is the unspoken secret — the family doesn't talk about it, which makes it feel like a presence in the room."

*[The AI validated the fourth attempt as a strong, sophisticated inference — but Oliver ran out of session time before the explanation card appeared.]*

### The parent notification

**Triggered because:** Sustained effort over 22 minutes with no abandonment despite significant difficulty. Four attempts at the same question showing iterative improvement. Effort quality, not outcome, triggered the notification.

> **From the learning app — Oliver's reading session tonight**
>
> Oliver spent 22 minutes this evening working on a reading question that he found genuinely hard.
>
> The question asked him to explain the phrase "loud with silence" in a novel extract — it's an oxymoron, and interpreting it properly requires reading several layers of the text at once.
>
> His first attempt: "it means it's quiet."
> His fourth attempt: "the silence is the unspoken secret — not talking about it makes it feel like a presence in the room."
>
> He got there himself, across four attempts, without giving up.
>
> We didn't get to the explanation card before the session ended — so if you ask him what he was doing tonight, he might say he "didn't get the answer." That's not quite right. He got very close to a sophisticated literary reading by working through it step by step.
>
> If it comes up: "loud with silence" is a technique called oxymoron — two contradictory words combined to create a new, complex meaning. Poets and novelists use it to describe emotional states that can't be described with simple words. The "silence" in the book is loaded with what isn't being said.

---

# What "Perfect" Looks Like — and What We Can Build

## Honest Assessment of Achievability

### Achievable now with a curriculum graph + current AI

**Content generation and voice adaptation** is tractable today. Given a curriculum node (e.g., "adding fractions with unlike denominators — Year 5"), a language model can reliably generate challenge cards, AI message cards, and explanation cards at the right vocabulary level, with appropriate voice adaptation between age groups. The tone calibration (warm/Y1, collegial/Y9) is something current models handle well with good prompting and examples.

**Productive failure sequencing** is also achievable. The pattern — challenge before explanation, explanation triggered by attempt — is a structural rule that can be implemented as feed-assembly logic. The AI does not need to read the child's mind; it needs to insert an explanation card after a challenge card, conditional on a response being received. The curriculum graph tells it which explanation is appropriate for which challenge.

**Hint progression** (metacognitive → strategic → procedural → reveal) is a four-state machine per question. This can be implemented as a deterministic scaffold: if the child has responded n times without a correct answer, offer hint level n. The content of each hint can be generated per question by the language model. This is achievable without a sophisticated learner model — it just requires tracking response count per question.

**Interleaving** is a scheduling problem. The curriculum graph already knows which topics are related and which are adjacent. A scheduling layer can deliberately pull from different branches in a session. The AI message card explaining the mixing ("I'm doing this on purpose — mixing three topics") is a generated text, not a hard technical problem.

**Delight cards** at a basic level — visual surprises, comedic animations, occasional breaks — are a design and product question more than a technical one. Triggering them from an engagement signal (sustained interaction time) requires only a session timer and a probability distribution. The content of the delight is a design asset, not an AI generation problem.

**Effort attribution language** is a generation constraint. Current models can be instructed reliably to avoid score-focused language and praise strategies rather than outcomes. This is a prompting and evaluation problem, not a capability problem. Regular automated testing of generated output against a rubric ("does this response mention a score or number? does it attribute to effort or strategy?") can catch failures.

---

### Requires additional data (learner model, response times, session history)

**Self-comparative feedback** — "two sessions ago you were making this error" — requires persistent session history. The AI needs to know what the child attempted previously, what errors occurred, and what progress was made. This is a learner model problem: structured storage of attempt history per curriculum node per learner, queryable by the AI at session time. Without this, self-comparative feedback is impossible. It is the single most data-hungry feature in these stories, and it is also one of the most pedagogically powerful.

**Forgetting normalisation** requires session timestamps and gap detection. This is simple to implement (last session date minus current date) but requires the data to exist. Once the timestamp is available, the AI message can be generated trivially. The challenge is in calibrating the threshold: what counts as a "gap"? A day? A week? Two weeks? This requires data on how forgetting curves behave for different concepts, which is available in the research literature and could be incorporated into the system as concept-specific decay rates.

**Stepping back to prerequisites** requires the curriculum graph to encode prerequisite relationships explicitly, and the learner model to flag repeated errors at a given node. If a child fails the carrying step in multiplication twice, the system needs to identify "carrying in addition" as the prerequisite node and route the child there. This is achievable if the graph is well-constructed — it is a routing problem, not a generation problem.

**On-a-roll scenario detection** requires real-time session analysis: response time, accuracy, consistency. This needs a lightweight session model running alongside the session, tracking these signals and triggering a difficulty escalation when the pattern is detected. It is technically straightforward but requires the real-time data pipeline to exist.

**Response-time signals** (detecting when a child pauses, rushes, backtracks) require client-side event logging beyond simple answer submission. This is an engineering decision: how much interaction data is captured per session? Keystroke-level data is possible but raises privacy questions, especially for under-13s under UK GDPR and COPPA. The minimum useful signal is time-to-first-response per question, which is much simpler to capture and interpret.

---

### Design challenges rather than technical ones

**The delight moment** is a design challenge. The technical trigger is simple; the content is hard. What visual or interactive surprise is surprising enough to be memorable, age-appropriate across a range, not patronising, not distracting from learning, and not predictable? This requires iteration with real children, not technical development. Getting this wrong risks making the app feel cheap or manipulative (the dark pattern version of delight) rather than genuinely surprising and joyful.

**Voice calibration at scale** is a design and evaluation challenge. Writing individual stories (as above) is feasible. Generating thousands of AI message cards at exactly the right tone for Year 1 vs Year 9 — warm but not patronising, collegial but not cold — and maintaining that quality at scale is a continuous evaluation problem. A rubric, a set of human raters, and regular automated testing are needed. This is editorial and quality-assurance work, not engineering work.

**No numbers, no progress bars, no leaderboards** is a design constraint that fights against product conventions. Every existing EdTech platform has streaks, scores, and badges. The urge to add them will be strong — from developers, from investors, from parents who want to "see how they're doing." Holding the line on this is a product and organisational challenge, not a technical one. The research case for removing extrinsic reward structures in intrinsic motivation contexts is strong; the commercial pressure against it is also strong. This is the design decision that is most likely to be eroded over time.

**Parent notifications** need to be genuinely content-rich and episodic without being overwhelming. The risk is falling into one of two failure modes: firing too often and becoming notifications that parents ignore, or firing too rarely and becoming invisible. The calibration of trigger conditions — what counts as notification-worthy — is a product design problem that requires user research with real parents, not an algorithm. The content itself (as shown in these stories) is straightforward to generate once the triggering condition is well-defined.

**The "micro-autonomy" moment** (as in the computing story: "Option A or Option B") requires the curriculum graph to encode branching paths — not just a linear sequence of nodes, but genuine forks that converge at the same learning objective. This is a content design problem: someone has to design two pedagogically valid routes to the same goal, and those routes have to be encoded in the graph. It is achievable but requires up-front content design work, not just AI generation.

---

### The single most important thing to get right first

**The learner model — specifically, per-node attempt history.**

Almost every high-leverage feature in these stories depends on knowing what the child has attempted before: self-comparative feedback, prerequisite stepping-back, forgetting normalisation, on-a-roll detection, hint level tracking. Without this, the AI is essentially amnesiac — it can generate excellent individual cards, but it cannot adapt to the individual child across sessions. It will repeat questions the child has already answered correctly, miss patterns in error types, and fail to provide the emotional resonance of "you didn't know this two weeks ago and now you do."

The curriculum graph tells the AI what to teach and in what order. The learner model tells it who it is teaching and how they are responding. Building the learner model first — even in a minimal form (which nodes has this child attempted, how many times, what was the last outcome, when was the last session) — unlocks the most important differentiated features. The graph without the learner model produces a very good fixed-sequence adaptive quiz. The graph plus the learner model produces something that can genuinely individualise.

The second priority — which this document has tried to demonstrate in practice — is the voice. Not the AI's capability to generate content, but the specific calibration of its tone to age. This requires a body of labelled examples (like these stories), a rubric, and consistent evaluation. It is the thing that will determine whether a 6-year-old feels the app is talking to them, or whether a 14-year-old rolls their eyes. Getting voice right is the difference between a product that children return to and one they tolerate.

Everything else — delight moments, delight triggers, sophisticated branching, response-time analysis — is valuable but derivative. Build the graph. Build the learner model. Get the voice right. The rest follows.
